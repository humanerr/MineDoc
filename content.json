{"meta":{"title":"Alex Technical Art","subtitle":"","description":"","author":"Alex Tsui","url":"https://cuihongzhi1991.github.io","root":"/blog/"},"pages":[{"title":"Real-Time Rendering 4th 笔记——第一章","date":"2020-04-11T12:33:36.000Z","updated":"2020-04-16T14:36:49.284Z","comments":true,"path":"DOING/RTR4Ch01.html","permalink":"https://cuihongzhi1991.github.io/DOING/RTR4Ch01.html","excerpt":"《Real-Time Rendering 4th》出版于2018年，是实时渲染圣经的第四版。此版涵盖的内容延续以往的结构，知识点到为止，展开的并不多。所以根据书中的索引可以对某一方面进行深度学习和研究。","text":"《Real-Time Rendering 4th》出版于2018年，是实时渲染圣经的第四版。此版涵盖的内容延续以往的结构，知识点到为止，展开的并不多。所以根据书中的索引可以对某一方面进行深度学习和研究。 引言实时渲染是计算机图形学交互性最强的领域。操作者做出操作或交互后可以立即得到反馈效果呈现在画面上，并根据产生的图像结果持续交互。这样一个操作与渲染的循环须有足够的计算速度才可以避免观察者看到多张不连贯的图像。图像显示速率以帧数/秒(FPS)或者赫兹(Hz)度量。每秒1帧几乎没有交互性；每秒6帧才有点交互性；游戏的目标是30、60、72或更高的FPS，例如游戏在VR头显设备运行时通常需要90FPS来最小化延迟避免产生眩晕感。实时渲染比交互性更重要，实时渲染一般指创造三维图像。交互性和三维空间关系是实时渲染的充分条件。后来，三维图形的加速硬件（显卡）也成为了实时渲染的第三个元素。不仅是电脑，平板和手机现在也内置了图形处理器。本书会着重提供可以加速和提升画面质量的方法，并且会描述加速算法和图形API的特性及限制。本书不会对每个话题深入讨论，而是展现其核心概念和专业术语，对最鲁棒和最实际的算法进行解释，并给出更多的拓展学习资料。 内容概括 第二章——图形渲染管线将场景的数据化抽象描述转换成我们可以看到的实际画面的步骤就是实时渲染的核心。 第三章——图形处理单元现代GPU使用固定方法与可编程单元的组合来实现渲染管线的各个步骤。 第四章——变换变换是修改物体位置、朝向、比例和形状的基本工具，也是修改相机位置和FOV的基本工具。 第五章——基础着色从讨论材质和灯光的含义开始，并实现写实或风格化的材质效果。另外还会介绍一些效果相关的话题，比如通过反走样、半透和伽马矫正得到质量更佳的图像。 第六章——纹理快速读取和在表面上显示图像的能力是实时渲染的强力工具之一。这个过程被称为纹理映射，有着很广泛的应用方法。 第七章——阴影给场景添加阴影既可以提升真实感也便于理解空间关系。本章会快速展示一下常用的计算阴影的算法。 第八章——光和色彩在呈现基于物理的渲染之前，需要理解如何量化光和色彩。在物理渲染过程结束后，需要转换结果为数值来展示效果，包括屏幕和观察环境的多种属性。 第九章——基于物理的着色本章会透彻讲解对基于物理的着色。会介绍背后的物理现象、各种渲染材质的数学模型、混合材质和反走样的过滤方法。 第十章——局部照明探索更精准的光照算法。当光源具有特殊形状时是如何计算表面的着色。 第十一章——全局照明模拟灯光和场景多次交互的算法大大增加图像的真实性。会讨论直接和间接光遮蔽以及渲染漫反射和镜面反射表面的全局光照的方法，还有一些可信的统一实现方式。 第十二章——图像效果图形硬件擅长快速处理图像。会先介绍图像过滤和重映射技术，然后讨论几个流行的后期处理效果，如：镜头炫光、运动模糊和景深。 第十三章——物体的其他描述形式三角形不总是描述物体最快和最真实的方式。还有一些基于图像、点云、体素和其他采样集合的方式都有各自的优点。 第十四章——体积和半透渲染重现体积感材质的理论和实践，他们是如何与光照进行交互的。从宏观的大范围氛围效果到微观如发丝的光照散射都有模拟。 第十五章——非真实感渲染让场景看起来真实只是渲染的方法之一。还可以探讨其他类型，如卡通着色、水彩风格等，线条和文本的生成技术也会在此讨论。 第十六章——多边形技术几何数据来源广泛，有时为了快速渲染和提高渲染质量会修改数据。本章会介绍描述和压缩多边形数据技术的多个方面。 第十七章——曲线和曲面更复杂的表面描述方式提供了其他的优点，比如可以在质量和渲染速度上做取舍、更加细致的描述以及生成平滑的表面。 第十八章——管线优化当应用程序使用高效的算法运行时，可以使用各种优化技术更快的运行。找到瓶颈并且决定如何解决瓶颈是本章的主题。多重处理也会在此讨论。 第十九章——加速算法不仅能运行，还要更快速。本章涵盖了各种剔除和LOD渲染方法。 第二十章——高效的着色方式在场景中，大量的光源会导致性能的下降。在片段可见性未知的情况下对其完整的渲染是浪费的。此处会探索一些可以解决这种低效着色的办法。 第二十一章——虚拟现实和增强现实该领域有其特殊的挑战和技术来实现真实、快速并且稳定的图像。 第二十二章——相交测试方法相交测试对渲染、玩家交互和碰撞检测都十分重要。本章会介绍很多几何体相交测试的高效算法。 第二十三章——图形硬件本章会介绍颜色深度、帧缓冲和基础的架构类型。给出了一个典型的GPU实例分析。 第二十四章——未来让我们猜猜看。 符号和定义TO DO 数学符号TO DO 几何定义TO DO 着色TO DO 其他学习资源Real-Time Rendering官网"},{"title":"UE4制作《地平线》体积云","date":"2020-04-17T15:30:14.000Z","updated":"2020-04-19T14:29:10.940Z","comments":true,"path":"DOING/VC-HZD2016.html","permalink":"https://cuihongzhi1991.github.io/DOING/VC-HZD2016.html","excerpt":"","text":"概览游戏中的实时体积云往往为了降低性能而降低质量。最成功的实现仅限于低空的蓬松半透的层状云。开发者提出一种有体积感的解决方案，可以用各种类型的云填满整个天空，十分真实。不仅描绘了高空的卷云，还有所有低云族的主要类型，包括厚的卷积云。另外，开发者的几中体积光效果的模拟方法还没有在这个体积云方案中呈现。最后，这个解决方案在内存和GPU开销方面表现得足够好，可以在3A的主机游戏中使用。 简介3A主机游戏云渲染的标准方案包括某些素材，比如2D公告板、带穹顶图的天空球或者体积素材库在渲染时进行实例化。像开放世界这样天空需要不断变化并且玩家视距非常远的游戏中，数据储存、多个相机角度、TOD和不同光照条件下的数据读取使得高细节资源的优势黯然失色。另外，云系统演化过程的模拟仅限于作假的方式，比如旋转天空球或者用2D噪波扭曲云的贴图。有许多不依赖资产的程序化云系统的技术。ShaderToy.com上有几个很好的免费案例，比如Quilez的“Clouds”。索尼的Evolution Studios在游戏《驾驶俱乐部》中使用TrueSky的插件呈现氛围感很强的天气效果。然而这种方式也有几个限制： 它们只描述了低高度的层云，不是蓬松汹涌的层积云或积云。 现有的方法没有针对特定的云实现真实的光照效果。 正常情况下，实时体积云性能开销很高，内存占用多，不值得为了质量好而牺牲这么多。对于游戏《地平线：黎明时分》，开发者研发了新的解决方案来解决上述的问题。他们为体积云的建模、光照和渲染提出了新的算法，在内存预算20MB和实时性能2ms的情况下实现真实和逐步演变的效果。 云的建模。。。。。。。。。。。。。。。。"},{"title":"categories","date":"2020-04-11T09:45:58.000Z","updated":"2020-04-11T09:54:15.732Z","comments":false,"path":"categories/index.html","permalink":"https://cuihongzhi1991.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-04-11T09:44:03.000Z","updated":"2020-04-11T09:54:17.823Z","comments":false,"path":"tags/index.html","permalink":"https://cuihongzhi1991.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"VEX101——VEX概览","slug":"vex101_overview","date":"2020-07-26T13:06:48.000Z","updated":"2020-07-26T04:05:09.441Z","comments":true,"path":"2020/07/26/vex101_overview/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/07/26/vex101_overview/","excerpt":"学习和使用VEX有一年多的时间了，近日翻到了2015年的一部VEX教程《VEX in Houdini》。曾经因为刚入门Houdini，还不适合学习这部教比较进阶甚至高级的教程。而现在又翻到它简直如获珍宝。它将很多paper中的算法在Houdini中用VEX来实现。这是读paper、学习算法以及落地实现的极佳机会。所以决定记录一下完整的学习笔记和心得。","text":"学习和使用VEX有一年多的时间了，近日翻到了2015年的一部VEX教程《VEX in Houdini》。曾经因为刚入门Houdini，还不适合学习这部教比较进阶甚至高级的教程。而现在又翻到它简直如获珍宝。它将很多paper中的算法在Houdini中用VEX来实现。这是读paper、学习算法以及落地实现的极佳机会。所以决定记录一下完整的学习笔记和心得。 什么是VEX仅可以在Houdini中使用的类C编程语言。但又不像C或C++那么底层，读写硬盘上的内容是有限制的，读取点云这种特殊形式的文件是可行并且速度很快的。一开始是作为Houdini的着色器编程语言开发出来的，后来也渐渐广泛应用于几何处理。VEX编写的小程序很像计算着色器，但是是在CPU上并行处理的。VEX也有可视化编程的方式——VOP，其中的逻辑会最终编译成VEX。 VEX的语境编辑几何数据一般在SOP环境下进行——surface operation。常用的数据是P, N, ptnum, Npt, Cd等。但更底层的几何数据则需要在CVEX语境下读写，也只能在此语境下创造新的几何体。 变量及类型基础的变量类型： float, int, string。没有double类型，并且精度也被限制在32-bit。线性代数类型：vector和matrix。扩展类型：array和struct。双向散射分布函数：bsdf。没有指针，不能直接访问内存，所以不会导致houdini崩溃。 流程控制分支：if, else if, else。循环：while, for, foreach。 函数与C语言类似： int foo(float a, b; int c){ // body returning an int }函数重载：int square_me(int a) { return a a; }float square_me(float a) { return a a; }一般情况下不做递归运算。 预编译include “vfl_code”define kPI 3.1415926pragmas","categories":[{"name":"Houdini","slug":"Houdini","permalink":"https://cuihongzhi1991.github.io/categories/Houdini/"}],"tags":[{"name":"Houdini","slug":"Houdini","permalink":"https://cuihongzhi1991.github.io/tags/Houdini/"},{"name":"VEX","slug":"VEX","permalink":"https://cuihongzhi1991.github.io/tags/VEX/"}]},{"title":"编写URP着色器","slug":"urpshadercode","date":"2020-06-08T13:06:48.000Z","updated":"2020-06-21T07:27:11.690Z","comments":true,"path":"2020/06/08/urpshadercode/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/06/08/urpshadercode/","excerpt":"本篇文章转自CYAN编写的《Writing Shader Code for the Universal RP》，文中以一个完整的PBR Shader为案例讲解了URP管线的一些机制以及编写Shader时的注意事项。可以帮助我们少踩一些坑。","text":"本篇文章转自CYAN编写的《Writing Shader Code for the Universal RP》，文中以一个完整的PBR Shader为案例讲解了URP管线的一些机制以及编写Shader时的注意事项。可以帮助我们少踩一些坑。 ShaderlabUnity中的着色器文件中，使用Shaderlab语义来定义着色器的Properties、SubShader以及Pass，Pass中实际的着色器代码使用HLSL编写。Shaderlab中的大多数内容相比过去的内置管线并没有改变太多，所以作者会以一个案例来拆解分析，而不会涉及太多细节的东西，可以通过官方文档查看更详细的内容。URP管线下需要注意的区别是“RenderPipeline”和“LightMode”的标签。着色器块如下方的形式： 1234Shader \"Custom/UnlitShaderExample\"&#123; ...&#125; 在其内部，我们需要一个Properties语义块和SubShader语义块(其中含有Pass语义块)： 12345678Properties&#123; // [参数名] (\"[材质面板上的名称]\", [类型]) = [默认值] _BaseMap (\"Base Texture\", 2D) = \"white\" &#123;&#125; _BaseColor (\"Base Color\", Color) = (0, 0.66, 0.73, 1) // _ExampleDir (\"Example Vector\", Vector) = (0, 1, 0, 0) // _ExampleFloat (\"Example Float(Vector1)\", Float) = 0.5&#125; “Properties”语义块是用来暴露需要显示在材质面板上的参数，这样同着色器生成的不同材质可以使用不同的贴图或颜色等等。 如果打算使用C#脚本来修改材质中的属性(如material.SetColor/SetFloat/SetVector等)，则不需要在Properties语义块中定义。然而如果需要每个物体拒用不同的参数值，则需要在Properties中定义，否则SRP Batcher试图使用未暴露的参数对对象进行批处理时会出现渲染BUG。如果不是每个对象使用不同的参数值，那么使用Shader.SetGlobalColor/Float/Vector则更加方便。 123456789101112131415161718192021SubShader&#123; Tags &#123; \"RenderType\" = \"Opaque\" \"Queue\" = \"Geometry\" \"RenderPipeline\" = \"UniversalRenderPipeline\" &#125; HLSLINCLUDE ... ENDHLSL Pass &#123; Name \"ExamplePass\" Tags &#123; \"LightMode\" = \"UniversalForward\" &#125; HLSLPROGRAM ... ENDHLSL &#125;&#125; Unity会使用当前设备GPU支持的第一个SubShader语义块的内容，由于我们的标签设置为“RenderPipeline” = “UniversalRenderPipeline”，所以在内置管线和HDRP管线下不会执行此SubShader，而会尝试着色器中余下的SubShader。如果没有可支持的SubShader，那么则会显示为品红色的错误提示着色器。“RenderType”标签在内置管线中实现Replacement Shader(URP不支持)时可以使用到。“Queue”标签指定物体渲染的顺序，可以用来指定半透材质物体的排序或用于模板(Stencil)相关的操作。可以在此处查看这些标签的信息。可以在SubShader中定义多个Pass语义块，但是每个Pass的”LightMode”标签必须指定特定的类型。URP使用single-pass的前向渲染方式，只有第一个标签为”UniversalForward”的Pass(当前GPU支持的)会用被来渲染物体，所以不能渲染多个同类型标签的Pass。如果使用无标签的Pass，会破坏SRP Batcher的批处理。所以建议分开使用着色器或材质，用于不同的MeshRenderers或在前向渲染器中使用RenderObjects特性在特定的层使用一个overrideMaterial重新绘制物体。 URP LightMode 标签：UniversalForward - 使用前向渲染器渲染物体ShadowCaster - 用于投射阴影DepthOnly - 用于渲染场景的深度纹理，一些渲染特性可能会用到Meta - 仅在烘焙光照贴图时使用Universal2D - 开启2D渲染器时使用UniversalGBuffer - 与延迟渲染有关，目前还在开发和测试中 Pass中还有一个”Name”，可以配合UsePass命令使用。其他着色器中存在一个你想使用的Pass时，使用这个方法就不需要再重复编写一次了。例如： 1UsePass \"Custom/UnlitShaderExample/EXAMPLEPASS\" 这个Pass就会被包含在你的着色器中。但是为了与SRP Batcher兼容，所有的pass都要共享相同的UnityPerMaterial CBUFFER，使用UsePass时如果CBUFFER数据不同则会出现问题(未来可能会修复)。下一小节会介绍CBUFFER。在Pass语义块中，也会常常看到Cull, ZWrite和ZTest。它们的默认值分别是Cull Back, ZWrite On和ZTest LEqual。半透队列中的着色器，还可以使用Blend(混合)操作。模板(Stencil)操作也可以在Pass语义块中定义。完整的Shaderlab语义块如下：123456789101112131415161718192021222324252627282930Shader \"Custom/UnlitShaderExample\" &#123; Properties &#123; _BaseMap (\"Example Texture\", 2D) = \"white\" &#123;&#125; _BaseColor (\"Example Colour\", Color) = (0, 0.66, 0.73, 1) //_ExampleDir (\"Example Vector\", Vector) = (0, 1, 0, 0) //_ExampleFloat (\"Example Float (Vector1)\", Float) = 0.5 &#125; SubShader &#123; Tags &#123; \"RenderType\"=\"Opaque\" \"Queue\"=\"Geometry\" \"RenderPipeline\"=\"UniversalRenderPipeline\" &#125; HLSLINCLUDE ... ENDHLSL Pass &#123; Name \"Example\" Tags &#123; \"LightMode\"=\"UniversalForward\" &#125; HLSLPROGRAM ... ENDHLSL &#125; &#125;&#125; HLSL实际的着色器代码是在ShaderLab的各个Pass中使用HLSL(high level shading language)编写的。内置管线的着色器基本都是使用CG语言编写的，但未来版本推荐使用HLSL，并且HDRP和URP管线的着色器都是基于HLSL的，可见未来将弃用CG语言。曾经使用的CGPROGRAM/CGINCLUDE和ENDCG在URP的着色器中要替换为HLSLPROGRAM/HLSLINCLUDE和ENDHLSL。因为CGPROGRAM等标签会自动包含一些内置的函数，会与URP中的一些函数产生重复定义的冲突。 标量类型变量HLSL中通常包含下述标量数据类型： bool——true或false。 float——32位浮点数。一般用于表示世界空间坐标和纹理坐标的单个元素的值；或者用于复杂的标量计算，如三角函数、幂函数和指数函数运算。 half——16位浮点数，一般用于表示较短的向量、方向、模型空间坐标和颜色的单个元素的值。 double——64位浮点数，不能用于输入或输出。 fixed——只在内置管线着色器中使用，URP不支持，使用half代替。 real——默认为half，如果定义了“#define PREFER_HALF 0”，那么则为float。 int——32位整数 uint——32位无符号整数(GLES2不支持。自动转为int类型) 向量类型变量 float2/3/4——每个元素都为float类型的二维/三维/四维向量。 half2/3/4——每个元素都为half类型的二维/三维/四维向量。 int2/3/4——每个元素都为int类型的二维/三维/四维向量。 可以使用.x/.y/.z/.w(或者.r/.g/.b/.a)获取向量的各个元素。并且也可以利用这种写法重新排布向量的构成。 12345678910float3 vector = float3(1, 2, 3);float3 a = vector.xyz; // (1, 2, 3), 即vector.rgbfloat3 b = vector3.zyx; // (3, 2, 1), 即vector.bgrfloat3 c = vector.xxx; // (1, 1, 1), 即vector.rrrfloat2 d = vector.zy; // (3, 2), 即vector.bgfloat4 e = vector.xxzz; // (1, 1, 3, 3), 即vector.rrbbfloat f = vector.y; // 2, 即vector.g // 但是杂交的表示法如\"vector.rx\"是不允许的。// 使用vector.rr或vector.xx代替。 矩阵矩阵可以用标量类型接数字X数字的形式表示，如float4x3。第一个数字4为矩阵的行数(row)，第二个数字3为矩阵的列数(column)。 float4x4——4 rows, 4 columns int4x3——4 rows, 3 columns half2x1——2 rows, 1 column float1x4——1 row, 4 colomns 可以提取矩阵的元素形成向量：123456789float3x3 matrix = &#123;0,1,2, 3,4,5, 6,7,8&#125;;float3 row0 = matrix[0]; // (0, 1, 2)float3 row1 = matrix[1]; // (3, 4, 5)float3 row2 = matrix[2]; // (6, 7, 8)float row1column2 = matrix[1][2]; // 5// Note we could also dofloat row1column2 = matrix[1].z; 矩阵经常用于不同坐标系的变换，所以常常会用到矩阵的乘法。矩阵与向量的乘法不能用*而要用mul(matrix, vector)来实现。12mul(GetObjectToWorldMatrix(), float4(positionOS, 1.0)).xyz;// GetObjectToWorldMatrix() 返回 \"UNITY_MATRIX_M\"，是Unity传入的模型矩阵 上方的方法其实就是TransformObjectToWorld()函数。一定要注意mul(x,y)的输入顺序，如果第一个输入为向量，那么会将其定义为行向量(row vector, 1 row n column)，放在第二个位置则认为它是列向量(column vector, n rows 1 column)。例如，float3向量放在x处，那么相当于float1x3的矩阵，放在y处则为float3x1的矩阵。 相乘的矩阵，第一个矩阵的列数要与第二个矩阵的行数相同。计算结果的行数与前者相同，列数与后者相同。例如，mul(float4x4, float4)的结果为float4x1，也就是float4。 数组着色器中是可以声明数组的，但是Shaderlab的属性和材质面板不支持显示，需要通过C#脚本来调整。数组的大小需要在着色器中声明，保证为常量来规避内存问题。如果还不确定数组需要的大小，可以设置一个最大值，或者通过一个float值来表示数组的长度。123float _Array[10]; // Float arrayfloat4 _Array[10]; // Vector arrayfloat4x4 _Array[10]; // Matrix array 可以在脚本中通过material.SetFloatArray或Shader.SetGlobalFloatArray来设置数组。另外还有SetVectorArray和SetMatrixArray以及设置全局的版本。 其他类型HLSL还包含一些类型如Texture和Sampler，可以在URP中通过宏定义：12TEXTURE2D(textureName);SAMPLER(sampler_textureName); 还有缓冲Buffer类型，可以在脚本中通过material.SetBuffer或Shader.SetGlobalBuffer设置。1234#ifdef SHADER_API_D3D11StructuredBuffer&lt;float3&gt; buffer;#endif// 查看 https://docs.unity3d.com/Manual/SL-ShaderCompileTargets.html流程控制的方法如if/for/while等与C#相同。 函数在HLSL中声明函数与C#相似，例如：123float3 example(float3 a, float3 b)&#123; return a * b;&#125; float3是返回类型，example是函数名，()中是输入参数，{}是函数体。 空返回类型使用void；可以使用”out”关键字定义输出参数，或者”inout”表示其为输入参数并对其进行修改后输出。可能会见到一些”inline”函数(内联函数)，表示编译器每次调用该内联函数处都会复制一份该函数，对于简短的函数，可以有效降低调用函数产生的开销。可能还会看到一些如下的函数形式：1#define EXAMPLE(x, y) ((x) * (y)) 这是macro(宏)，宏会在编前将调用宏的地方替换成宏指向的原意。1234567891011121314151617float f = EXAMPLE(3, 5);float3 a = float3(1,1,1);float3 f2 = EXAMPLE(a, float3(0,1,0)); // 变为：float f = ((3) * (5));float a = float(1,1,1);float3 f2 = ((a) * (float3(0,1,0)));// 然后编译着色器 // 注意宏中的x和y都加了括号// 那么：float b = EXAMPLE(1+2, 3+4);// 变为：float b = ((1+2) * (3+4)); // 3 * 7, so 21// 如果不加括号，那么就会是如下的结果：float b = (1+2*3+4) 宏还有函数不好实现的用法，例如：1234567#define TRANSFORM_TEX(tex,name) (tex.xy * name##_ST.xy + name##_ST.zw) // 使用：OUT.uv = TRANSFORM_TEX(IN.uv, _MainTex) // 变为：OUT.uv = (IN.uv.xy * _MainTex_ST.xy + _MainTex_ST.zw); “##”标识符在宏中获取名称及_ST部分，生成_MainTex_ST。当然，_MainTex_ST仍然需要定义。 开始编写着色器着色器通常包含两个阶段，顶点着色器(vertex shader)和片元着色器(fragment shader)。模型的每个顶点都会运行顶点着色器，屏幕将会显示的每个像素都会运行片元着色器。一些片元可能会被丢弃掉(如alpha裁切和模板着色器)，所以不会成为最终的像素(因此有人不喜欢称片元着色器为像素着色器)。另外还有壳/域着色器、几何着色器和计算着色器，暂不讨论。这些着色器在URP和内置管线的工作方式是一样的。在着色器中，使用HLSLINCLUDE包含的代码会在SubShader中的每个Pass被自动包含进来。不是必须的，但使用SRP Batcher时，如UnityPerMaterial CBUFFER这样每pass相同的内容使用HLSLINCLUDE则非常合适。CBUFFER需要包含暴露的所有属性(与Shaderlab属性语义块中定义的一致)，不可以包含没有暴露的属性，纹理不需要被包含在CBUFFER中。使用material.SetColor/SetFloat/SetVector等等函数可以在C#脚本中实现对未暴露参数的修改。但是使用SRP Batcher对多个带有不同数值的材质示例进行批处理时会产生问题。使用Shader.SetGlobalColor/Float/Vector等函数可以规避此问题，但如果一定需要每个材质示例带有不同数值，那么必须要暴露属性并在CBUFFER中定义。12345678910HLSLINCLUDE #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" CBUFFER_START(UnityPerMaterial) float4 _BaseMap_ST; float4 _BaseColor; //float4 _ExampleDir; //float _ExampleFloat; CBUFFER_ENDENDHLSL 上方代码包含了URP ShaderLibrary中的Core.hlsl，类似于内置管线的UnityCG.cginc。此文件中也自动包含了一些其他的库文件，其中包含大量有用和常用的函数与宏。在HLSLPROGRAM中首先要做的就是声明顶点着色器和片元着色器。通常用”vert”和”frag”作为两者的名字，当然可以随意定义。 12345678HLSLPROGRAM #pragma vertex vert#pragma fragment frag ... ENDHLSL 在定义这俩函数之前，经常需要定义两个结构体。会在下个小节介绍。 结构体在定义顶点着色器和片元着色器之前，需要定义一些用于传输数据的结构体。在内置管线中，这些结构体往往命名为“appdata”和“v2f”(vertex to fragment的简写)，在URP中，官方使用的是“Attributes”和“Varyings”。这些名称可以随意命名，但为了协作方便，往往遵循统一的命名规则。URP的ShaderLibrary中也使用一些结构体来组织函数中需要的数据。例如光照和着色计算中需要的InputData和SurfaceData，将会在光照部分讨论这些。因为第一个案例是Unlit着色器，所以结构体比较简单。12345struct Attributes &#123; float4 positionOS : POSITION; float2 uv : TEXCOORD0; float4 color : COLOR;&#125;; Attributes结构体包含了传入顶点着色器的数据。将模型每个顶点的数据传入顶点着色器，使用大写的宏来实现。通常包括顶点位置(POSITION)，顶点颜色(COLOR)，纹理坐标——UV(TEXCOORD)。一个模型拥有8个不同的UV通道，通过TEXCOORD0到TEXCOORD7读取。Mesh.uv是TEXCOORD0，没有Mesh.uv1，下一个通道是Mesh.uv2，即TEXCOORD1。因此Mesh.uv8对应的是TEXCOORD7。也可以通过NORMAL读取顶点的法线，通过TANGENT读取切线。在Unlit着色器中很少用到。12345struct Varyings &#123; float4 positionCS : SV_POSITION; float2 uv : TEXCOORD0; float4 color : COLOR;&#125;; Varyings结构体包含顶点着色器输出的数据，并且作为片元着色器的输入数据的结构体(假设中间不存在几何着色器，否则需要额外的结构体，本篇不会涉及到)。定义好结构体后，一般还会定义需要用的纹理和纹理采样器(属性语义块中纹理之外的属性在CBUFFER中定义)。12TEXTURE2D(_BaseMap);SAMPLER(sampler_BaseMap); 顶点着色器顶点着色器一个重要任务是将模型顶点位置从模型空间转换到剪裁空间。这样才可以正确渲染将要显示在屏幕上的片元/像素。在内置管线中使用UnityObjectToClipPos函数可以实现该操作，在URP中使用TransformObjectToHClip函数来代替(SpaceTransforms.hlsl)。另外也可以使用下属方式来获取剪裁空间的位置。123456789101112Varyings vert(Attributes IN) &#123; Varyings OUT; VertexPositionInputs positionInputs = GetVertexPositionInputs(IN.positionOS.xyz); OUT.positionCS = positionInputs.positionCS; // 或者： //OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz); OUT.uv = TRANSFORM_TEX(IN.uv, _BaseMap); OUT.color = IN.color; return OUT;&#125; 使用函数GetVertexPositionInputs可以获取各种空间的位置信息。在URP管线的ShaderVariablesFunctions.hlsl中可以查看该函数的实现方式。包含Core.hlsl会自动包含该文件。输入Attributes中的模型空间坐标，得到VertexPositionInputs结构体，它包含了下述位置信息： positionWS，世界空间坐标 positionVS，观察空间坐标 positionCS，剪裁空间坐标 positionNDC，归一化设备坐标系中的坐标 Unlit着色器中不需要其他那些坐标信息，因此在编译时它们不会被编译，因此不会产生额外的计算开销。顶点着色器的其他任务还包括将顶点数据传入到片元着色器，如顶点色OUT.color = IN.color。如果需要采样纹理，那么还需要传输模型的UV。使用OUT.uv = IN.uv来实现(假设都是float2)。经常会使用TRANSFORM_TEX宏来实现在材质面板控制纹理采样器的UV偏移和平铺。如_BaseMap_ST，S是scale；T是translate。在内置管线和URP中都可以使用该宏(core/ShaderLibrary/Macros.hlsl)。这个宏的作用其实是IN.uv.xy * _BaseMap_ST.xy + _BaseMap_ST.zw。但要注意的是TextureName_ST这个float4需要在CBUFFER中定义。获取法线的函数与获取位置的函数类似：1VertexNormalInputs normalInputs = GetVertexNormalInputs(IN.normalOS, IN.tangentOS); GetVertexNormalInputs函数可以将模型空间的法线和切线转换到世界空间。VertexNormalInputs包含了normalWS, tangentWS和bitangentWS三个向量。另外可以使用TransformObjectToWorldNormal(IN.normalOS)函数将模型空间法线转换到世界空间。 片元着色器片元着色器主要负责决定像素的颜色(包括alpha)。对于Unlit着色器来说，可以是简单的纯色，也可以是采样纹理后的颜色。对于Lit着色器，会稍微复杂一些。但URP管线提供了一些方便的函数，会在光照小节讨论。三角面上的片元/像素的数据由组成该三角面的三个顶点在Varyings中的数据进行线性插值来决定。因此，如果三个顶点从顶点着色器输出的颜色分别是(1, 0, 0), (0, 1, 0)和(0, 0, 1)，那么片元着色器得到的颜色则如下图： 如果对顶点法线进行线性插值(用于光照和着色计算)，那么插值后的法线很可能不是单位向量。结果类似于重心坐标系统，中心(0.33, 0.33, 0.33)的长度是0.577左右，而不是长度为1的单位向量。因此片元着色器获取插值后的法线需要先进行标准化。当然很多时候插值后的法向量的长度接近1，如果想简化计算，可以不进行标准化。那么现在Unlit材质的像素着色器如下：12345half4 frag(Varyings IN) : SV_Target &#123; half4 baseMap = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, IN.uv); return baseMap * _BaseColor * IN.color;&#125; 该着色器输出类型为half4，颜色由纹理颜色、基础色和顶点色共同决定。SV_Target语义表示结果作为片元着色器最终的输出颜色。另外还有类型为float的SV_Depth，用于重写每像素的Z缓冲值。一些GPU为了优化考虑，深度缓冲默认是关闭的。片元着色器中使用SAMPLE_TEXTURE2D宏对纹理进行采样，该宏由URP的ShaderLibrary提供，输入参数是纹理、纹理采样器和UV。另外也可以将像素alpha值低于某特定阈值的像素丢弃掉，那么那部分的模型就不可见。例如四边面片制作的草和树叶。丢弃像素的过程在不透明材质和半透材质中都可以实现，也是常说的alpha剪裁/剔除(clip/cutoff)。材质中可以使用_Cutoff属性可以控制该阈值，不仅要在属性语义块中定义，还要在CBUFFER中定义。 123456if (_BaseMap.a &lt; _Cutoff)&#123; discard;&#125;// 或者clip(_BaseMap.a - _Cutoff);// 在片元着色器函数中使用 那么目前为止无光照的着色器的完整代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768// Example Shader for Universal RP// Written by @Cyanilux// https://cyangamedev.wordpress.com/urp-shader-code/Shader \"Custom/UnlitShaderExample\" &#123; Properties &#123; _BaseMap (\"Example Texture\", 2D) = \"white\" &#123;&#125; _BaseColor (\"Example Colour\", Color) = (0, 0.66, 0.73, 1) //_ExampleDir (\"Example Vector\", Vector) = (0, 1, 0, 0) //_ExampleFloat (\"Example Float (Vector1)\", Float) = 0.5 &#125; SubShader &#123; Tags &#123; \"RenderType\"=\"Opaque\" \"RenderPipeline\"=\"UniversalRenderPipeline\" &#125; HLSLINCLUDE #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" CBUFFER_START(UnityPerMaterial) float4 _BaseMap_ST; float4 _BaseColor; //float4 _ExampleDir; //float _ExampleFloat; CBUFFER_END ENDHLSL Pass &#123; Name \"Example\" Tags &#123; \"LightMode\"=\"UniversalForward\" &#125; HLSLPROGRAM #pragma vertex vert #pragma fragment frag struct Attributes &#123; float4 positionOS : POSITION; float2 uv : TEXCOORD0; float4 color : COLOR; &#125;; struct Varyings &#123; float4 positionCS : SV_POSITION; float2 uv : TEXCOORD0; float4 color : COLOR; &#125;; TEXTURE2D(_BaseMap); SAMPLER(sampler_BaseMap); Varyings vert(Attributes IN) &#123; Varyings OUT; VertexPositionInputs positionInputs = GetVertexPositionInputs(IN.positionOS.xyz); OUT.positionCS = positionInputs.positionCS; // Or this : //OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz); OUT.uv = TRANSFORM_TEX(IN.uv, _BaseMap); OUT.color = IN.color; return OUT; &#125; half4 frag(Varyings IN) : SV_Target &#123; half4 baseMap = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, IN.uv); return baseMap * _BaseColor * IN.color; &#125; ENDHLSL &#125; &#125;&#125; 关键字和着色器变体讨论光照之前，先谈谈着色器中的关键字(keyword)和变体(variant)，在URP ShaderLibrary中使用的非常多，所以知道关键字和变体的机制十分有意义，这样才能正确处理光照的函数。在着色器中，可以声明很多#pragma指令，带有multi-compile和shader_feature指令可以控制关键字是否开启，控制着色器某些部分生效与否。这样着色器会编译出多个版本，也就是着色器的变体。 multi_compile1#pragma multi_compile _A _B _C (...etc) 这个示例中，我们会产生三种变体，_A，_B和_C是关键字。那么在着色器的代码中，用法如下： 123456789101112131415161718#ifdef _A// 如果开启A，则编译此段代码#endif #ifndef _B// 如果B没开启，也就是开启了A和C，那么编译此段代码。#ifndef表示没有定义#else// 否则表示B开启了，编译此段代码#endif #if defined(_A) || defined(_C)// 开启了A或者开启了C，则编译此段代码。// 像这样有复合判断条件的情况，需要使用#if defined()。// 但要注意的是，因为这几个关键字是在同一个multi_compile中定义的，因此不会出现&amp;&amp;的情况// 即不能存在A &amp;&amp; B, A &amp;&amp; C, B &amp;&amp; C#endif // 另外else if在HLSL中是#elif shader_feature1#pragma shader_feature _A _B 与multi_compile的机制一样，但区别是最终的打包版本不包含没有使用的变体。因此，在运行时开启或关闭这些关键字是不合理的，因为有些变体代码没有被编译进最终的版本。如果要在运行时处理某些关键字，那么要使用multi_compile来代替。 着色器变体每增加一个multi_compile和shader_feature，都会增加更多的着色器变体。下方的例子中：123#pragma multi_compile _A _B _C#pragma multi_compile _D _E#pragma shader_feature _F _G 第一行存在三种可能性，但是第二行又有两种可能性。因此会出现6种不同的组合方式:A &amp; D, A &amp; E, B &amp; D, B &amp; E, C &amp; D and C &amp; E第三行又有两种可能性。因此现在一共有12种不同的组合。但因为使用的是shader_feature，因此有些变体不会存在与最终的打包版本中。每增加一个带有两个变体的multi_compile都会使最终的组合翻倍。10个这样的multi_compile就会产生1024个着色器变体组合。每个组合都会出现在最终的包体中，那么编译时间也会增加，包体大小也会增加。如果想查看一个着色器存在多少种变体，可以点击材质面板的”Compile and Show Code”按钮，便会看到变体的数量。如果点击”skip unused shader_feature”可以切换是否查看全部的变体。上述的指令也有针对顶点着色器和片元着色器的版本，这样可以有效减少最终变体组和的数量，优化包体和编译时间。例如：1234#pragma multi_compile_vertex _ _A#pragma multi_compile_fragment _ _B#pragma shader_feature_vertex _ _C#pragma shader_feature_fragment _ _D 关键字的上限每个工程关键字的数量最多为256，所以最好遵循通用的关键字便于协作。另外有时会看到multi_compile和shader_feature后面会接”_”，这并不会产生额外的关键字。123456789101112#pragma multi_compile _ _KEYWORD #pragma shader_feature _KEYWORD// 其实就是下面的简写#pragma shader_feature _ _KEYWORD // 如果想知道关键字是否禁用，可以使用：#ifndef _KEYWORD// 或者 #if !defined(_KEYWORD)// 或者 #ifdef _KEYWORD #else// 代码#endif 为了防止超过关键字的最大上限，可以使用multi_compile和shader_feature的局部版本。这些关键字只会在当前着色器中有效，每个着色器的局部关键字的上限是64。123456#pragma multi_compile_local _ _KEYWORD#pragma shader_feature_local _KEYWORD// 当然局部关键字也有vertex和fragment版本#pragma multi_compile_local_fragment _ _KEYWORD#pragma shader_feature_local_vertex _KEYWORD 光照在内置管线中，需要处理光照和着色的着色器为Surface Shader。可以选择不同的光照模型，如physically-based Standard和StandardSpecular或者Lambert(diffuse)和BlinnPhong(specular)模型。也可以编写自定义的光照模型，例如卡通着色。 URP管线不支持surface shader，但ShaderLibrary提供了一些函数来辅助处理很多常用的光照计算。这些函数包含在Lighting.hlsl文件中，需要自己在代码中包含。 UniversalFragmentPBR函数可以处理基于物理的光照着色，下一节介绍。现在仅讨论主平行光的简单光照和阴影。在Lighting.hlsl中的函数GetMainLight()可以获取主要平行光的数据，那么需要先包含Lighting.hlsl，并且在HLSLPROGRAM后添加几个multi_compile指令来提供一些控制接受阴影的关键字。 12345#pragma multi_compile _ _MAIN_LIGHT_SHADOWS#pragma multi_compile _ _MAIN_LIGHT_SHADOWS_CASCADE#pragma multi_compile _ _SHADOWS_SOFT #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl\" 下面，我们需要顶点法线来处理光照和着色，所以在结构体中添加该属性，并且更新顶点着色器。下面的代码是新增的部分： 12345678910111213141516171819202122struct Attributes &#123; ... float4 normalOS : NORMAL;&#125;; struct Varyings &#123; ... float3 normalWS : NORMAL; float3 positionWS : TEXCOORD2;&#125;;...Varyings vert(Attributes IN) &#123; Varyings OUT; VertexPositionInputs positionInputs = GetVertexPositionInputs(IN.positionOS.xyz); ... OUT.positionWS = positionInputs.positionWS; VertexNormalInputs normalInputs = GetVertexNormalInputs(IN.normalOS.xyz); OUT.normalWS = normalInputs.normalWS; return OUT;&#125; 在片元着色器，可以获取世界空间的法向量，并且使用世界空间的位置来计算阴影坐标(当然可以在顶点着色器中计算阴影坐标然后传入片元着色器，但仅在shadow cascades关键字禁用时有效)。现在就暂且保持简单的方式。 1234567891011half4 frag(Varyings IN) : SV_Target &#123; half4 baseMap = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, IN.uv); half4 color = baseMap * _BaseColor * IN.color; float4 shadowCoord = TransformWorldToShadowCoord(IN.positionWS.xyz); Light light = GetMainLight(shadowCoord); half3 diffuse = LightingLambert(light.color, light.direction, IN.normalWS); return half4(color.rgb * diffuse * light.shadowAttenuation, color.a);&#125; 同时，我们的着色器也需要接受从其他着色器而来的阴影，但现在没有ShadowCaster pass，所以不会对自身和其他物体产生阴影，见下一节。如果仅需要阴影而不需要漫反射，那么可以移除漫反射光照计算，只使用light.shadowAttenuation。如果想进一步扩展，可以包含环境光或烘焙的全局光照以及其他额外的灯光，可将Lighting.hlsl中的UniversalFragmentBlinnPhong函数作为参考示例。也可以直接使用这个函数，需要InputData结构体作为输入，也是PBR着色案例中需要使用的结构体。 PRB光照基于物理的渲染Physically Based Rendering(PBR)是Unity的”Standard”着色器使用的着色模型，也就是URP的Lit着色器以及Shader Graph中的 PBR Master节点。前一节提过，内置管线的光照通过Surface Shader处理，”Standard”选项就是一个PBR模型。使用一个surface函数输出Albedo, Normal, Emission, Smoothness, AO, Alpha和Metallic(使用StandardSpecular流程则是Specular)。Unity会使用这些数据生成一个顶点着色器和片元着色器，处理PBR的光照计算和阴影计算。URP管线不支持surface着色器，然而ShaderLibrary提供了帮助计算光照的函数。Lighting.hlsl中与PBR着色相关的函数有： 1234567half4 UniversalFragmentPBR(InputData inputData, half3 albedo, half metallic, half3 specular, half smoothness, half occlusion, half3 emission, half alpha) half4 UniversalFragmentPBR(InputData inputData, SurfaceData surfaceData) half4 UniversalFragmentBlinnPhong(InputData inputData, half3 diffuse, half4 specularGloss, half smoothness, half3 emission, half alpha) 首先定义PBR着色需要的属性，暂且不引入metallic/specular和occlusion贴图，因为URP提供的函数对这两种贴图的处理不是很好。1234567891011121314151617181920212223242526Properties &#123; _BaseMap (\"Base Texture\", 2D) = \"white\" &#123;&#125; _BaseColor (\"Example Colour\", Color) = (0, 0.66, 0.73, 1) _Smoothness (\"Smoothness\", Float) = 0.5 [Toggle(_ALPHATEST_ON)] _EnableAlphaTest(\"Enable Alpha Cutoff\", Float) = 0.0 _Cutoff (\"Alpha Cutoff\", Float) = 0.5 [Toggle(_NORMALMAP)] _EnableBumpMap(\"Enable Normal/Bump Map\", Float) = 0.0 _BumpMap (\"Normal/Bump Texture\", 2D) = \"bump\" &#123;&#125; _BumpScale (\"Bump Scale\", Float) = 1 [Toggle(_EMISSION)] _EnableEmission(\"Enable Emission\", Float) = 0.0 _EmissionMap (\"Emission Texture\", 2D) = \"white\" &#123;&#125; _EmissionColor (\"Emission Colour\", Color) = (0, 0, 0, 0) &#125;...CBUFFER_START(UnityPerMaterial) float4 _BaseMap_ST; float4 _BaseColor; float _BumpScale; float4 _EmissionColor; float _Smoothness; float _Cutoff;CBUFFER_END 需要添加需要的multi_compile, shader_feature，调整Attributes和Varyings结构体。属性语义块中定义的TOGGLE属性允许材质编辑器对shader_feature进行开启或禁用。另外可以编写自定义的材质面板UI。如果想要支持构建光照贴图，还需要传入光照贴图UV。另外作者引入了ShaderLibrary中的SurfaceInput.hlsl和SurfaceData.hlsl，其中的SurfaceData结构体可以作为PBR着色需要的数据的载体，并且有一些对不同贴图采样的函数。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#pragma shader_feature _NORMALMAP#pragma shader_feature _ALPHATEST_ON#pragma shader_feature _ALPHAPREMULTIPLY_ON#pragma shader_feature _EMISSION//#pragma shader_feature _METALLICSPECGLOSSMAP//#pragma shader_feature _SMOOTHNESS_TEXTURE_ALBEDO_CHANNEL_A//#pragma shader_feature _OCCLUSIONMAP //#pragma shader_feature _SPECULARHIGHLIGHTS_OFF//#pragma shader_feature _ENVIRONMENTREFLECTIONS_OFF//#pragma shader_feature _SPECULAR_SETUP#pragma shader_feature _RECEIVE_SHADOWS_OFF // URP 关键字#pragma multi_compile _ _MAIN_LIGHT_SHADOWS#pragma multi_compile _ _MAIN_LIGHT_SHADOWS_CASCADE#pragma multi_compile _ _ADDITIONAL_LIGHTS_VERTEX _ADDITIONAL_LIGHTS#pragma multi_compile _ _ADDITIONAL_LIGHT_SHADOWS#pragma multi_compile _ _SHADOWS_SOFT#pragma multi_compile _ _MIXED_LIGHTING_SUBTRACTIVE // Unity 定义的关键字#pragma multi_compile _ DIRLIGHTMAP_COMBINED#pragma multi_compile _ LIGHTMAP_ON#pragma multi_compile_fog #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl\"#include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/SurfaceInput.hlsl\" struct Attributes &#123; float4 positionOS : POSITION; float3 normalOS : NORMAL; float4 tangentOS : TANGENT; float4 color : COLOR; float2 uv : TEXCOORD0; float2 lightmapUV : TEXCOORD1;&#125;; struct Varyings &#123; float4 positionCS : SV_POSITION; float4 color : COLOR; float2 uv : TEXCOORD0; DECLARE_LIGHTMAP_OR_SH(lightmapUV, vertexSH, 1); #ifdef REQUIRES_WORLD_SPACE_POS_INTERPOLATOR float3 positionWS : TEXCOORD2;#endif float3 normalWS : TEXCOORD3;#ifdef _NORMALMAP float4 tangentWS : TEXCOORD4;#endif float3 viewDirWS : TEXCOORD5; half4 fogFactorAndVertexLight : TEXCOORD6; // x: fogFactor, yzw: vertex light#ifdef REQUIRES_VERTEX_SHADOW_COORD_INTERPOLATOR float4 shadowCoord : TEXCOORD7;#endif&#125;; //TEXTURE2D(_BaseMap);//SAMPLER(sampler_BaseMap);// 移除，因为SurfaceInput.hlsl定义了_BaseMap 那么顶点着色器也需要更新：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#if SHADER_LIBRARY_VERSION_MAJOR &lt; 9 // This function was added in URP v9.x.x versions // If we want to support URP versions before, we need to handle it instead. // Computes the world space view direction (pointing towards the viewer). float3 GetWorldSpaceViewDir(float3 positionWS) &#123; if (unity_OrthoParams.w == 0) &#123; // Perspective return _WorldSpaceCameraPos - positionWS; &#125; else &#123; // Orthographic float4x4 viewMat = GetWorldToViewMatrix(); return viewMat[2].xyz; &#125; &#125;#endif Varyings vert(Attributes IN) &#123; Varyings OUT; // 顶点位置 VertexPositionInputs positionInputs = GetVertexPositionInputs(IN.positionOS.xyz); OUT.positionCS = positionInputs.positionCS;#ifdef REQUIRES_WORLD_SPACE_POS_INTERPOLATOR OUT.positionWS = positionInputs.positionWS;#endif // UVs &amp; 顶点色 OUT.uv = TRANSFORM_TEX(IN.uv, _BaseMap); OUT.color = IN.color; // 观察方向 OUT.viewDirWS = GetWorldSpaceViewDir(positionInputs.positionWS); // 法线和切线 VertexNormalInputs normalInputs = GetVertexNormalInputs(IN.normalOS, IN.tangentOS); OUT.normalWS = normalInputs.normalWS;#ifdef _NORMALMAP real sign = IN.tangentOS.w * GetOddNegativeScale(); OUT.tangentWS = half4(normalInputs.tangentWS.xyz, sign);#endif // 顶点光照 &amp; 雾 half3 vertexLight = VertexLighting(positionInputs.positionWS, normalInputs.normalWS); half fogFactor = ComputeFogFactor(positionInputs.positionCS.z); OUT.fogFactorAndVertexLight = half4(fogFactor, vertexLight); // 烘焙光照 &amp; 球谐函数(没有烘焙灯光情况下的环境光照) OUTPUT_LIGHTMAP_UV(IN.lightmapUV, unity_LightmapST, OUT.lightmapUV); OUTPUT_SH(OUT.normalWS.xyz, OUT.vertexSH); // 阴影坐标#ifdef REQUIRES_VERTEX_SHADOW_COORD_INTERPOLATOR OUT.shadowCoord = GetShadowCoord(positionInputs);#endif return OUT;&#125; 下面更新片元着色器，使用UniversalFragmentPBR函数，需要InputData结构体传入数据，我们不在片元着色器中创建和设置相关数据，而是封装另外一个函数，也会为贴图处理封装另外一个函数。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758InputData InitializeInputData(Varyings IN, half3 normalTS)&#123; InputData inputData = (InputData)0; #if defined(REQUIRES_WORLD_SPACE_POS_INTERPOLATOR) inputData.positionWS = IN.positionWS;#endif half3 viewDirWS = SafeNormalize(IN.viewDirWS);#ifdef _NORMALMAP float sgn = IN.tangentWS.w; // should be either +1 or -1 float3 bitangent = sgn * cross(IN.normalWS.xyz, IN.tangentWS.xyz); inputData.normalWS = TransformTangentToWorld(normalTS, half3x3(IN.tangentWS.xyz, bitangent.xyz, IN.normalWS.xyz));#else inputData.normalWS = IN.normalWS;#endif inputData.normalWS = NormalizeNormalPerPixel(inputData.normalWS); inputData.viewDirectionWS = viewDirWS; #if defined(REQUIRES_VERTEX_SHADOW_COORD_INTERPOLATOR) inputData.shadowCoord = IN.shadowCoord;#elif defined(MAIN_LIGHT_CALCULATE_SHADOWS) inputData.shadowCoord = TransformWorldToShadowCoord(inputData.positionWS);#else inputData.shadowCoord = float4(0, 0, 0, 0);#endif inputData.fogCoord = IN.fogFactorAndVertexLight.x; inputData.vertexLighting = IN.fogFactorAndVertexLight.yzw; inputData.bakedGI = SAMPLE_GI(IN.lightmapUV, IN.vertexSH, inputData.normalWS); return inputData;&#125; SurfaceData InitializeSurfaceData(Varyings IN)&#123; SurfaceData surfaceData = (SurfaceData)0; // 数字0会自动初始化结构体数据为0。 half4 albedoAlpha = SampleAlbedoAlpha(IN.uv, TEXTURE2D_ARGS(_BaseMap, sampler_BaseMap)); surfaceData.alpha = Alpha(albedoAlpha.a, _BaseColor, _Cutoff); surfaceData.albedo = albedoAlpha.rgb * _BaseColor.rgb * IN.color.rgb; surfaceData.smoothness = _Smoothness; surfaceData.normalTS = SampleNormal(IN.uv, TEXTURE2D_ARGS(_BumpMap, sampler_BumpMap), _BumpScale); surfaceData.emission = SampleEmission(IN.uv, _EmissionColor.rgb, TEXTURE2D_ARGS(_EmissionMap, sampler_EmissionMap)); surfaceData.occlusion = 1; return surfaceData;&#125; half4 frag(Varyings IN) : SV_Target &#123; SurfaceData surfaceData = InitializeSurfaceData(IN); InputData inputData = InitializeInputData(IN, surfaceData.normalTS); half4 color = UniversalFragmentPBR(inputData, surfaceData); color.rgb = MixFog(color.rgb, inputData.fogCoord); color.a = saturate(color.a); return color;&#125; 现在我们的着色器可以接收阴影，但因为没有ShadowCaster pass，所以不会对自己及其他物体产生投影，将在下一小节讨论。 ShadowCaster和DepthOnly PassShadowCaster如果希望着色器投影，需要一个标签为”LightMode”=”ShadowCaster”的pass。在Unlit和Lit着色器中都可以使用，但这仅仅是投影功能，如果需要接收阴影，那么就是上文中UniversalForward pass中的做法。并且着色器中还需要一个标签为”LightMode”=”DepthOnly”的pass。这个pass与ShadowCaster十分类似，但是不带阴影偏移。这个pass可能是自定义的Render Feature会用到的深度pass。着色器中所有的pass都共享同一个UnityPerMaterial CBUFFER使得SRP Batcher起作用。在前面的章节，我们将此缓冲放在HLSLINCLUDE中，所以会自动被包含在着色器的各个pass中。如果使用UsePass调取其他着色器中的ShadowCaster或者DepthOnly pass，可能会因为CBUFFER数据不统一导致SRP Batcher做批处理时出现一些问题。1234567891011121314151617181920212223242526Pass &#123; Name \"ShadowCaster\" Tags &#123; \"LightMode\"=\"ShadowCaster\" &#125; ZWrite On ZTest LEqual HLSLPROGRAM #pragma prefer_hlslcc gles #pragma exclude_renderers d3d11_9x gles #pragma shader_feature _ALPHATEST_ON #pragma shader_feature _SMOOTHNESS_TEXTURE_ALBEDO_CHANNEL_A #pragma multi_compile_instancing #pragma multi_compile _ DOTS_INSTANCING_ON #pragma vertex ShadowPassVertex #pragma fragment ShadowPassFragment #include \"Packages/com.unity.render-pipelines.core/ShaderLibrary/CommonMaterial.hlsl\" #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/SurfaceInput.hlsl\" #include \"Packages/com.unity.render-pipelines.universal/Shaders/ShadowCasterPass.hlsl\" ENDHLSL&#125; 包含URP管线中的ShadowCasterPass.hlsl，需要定义_BaseMao, _BaseColor和_Cutoff属性，CBUFFER中也需要定义。在片元着色器中，ShadowCaster会在有阴影的地方返回0，并且丢弃没有任何阴影信息的像素(剪裁只会在_ALPHATEST_ON关键字开启的情况下发生)，可以查看com.unity.render-pipelines.universal/Shaders/ShadowCasterPass.hlsl中的代码。如果着色器的pass中做了顶点的置换偏移操作，那么也需要将此操作实现于ShadowCaster的pass中，这样会将偏移后的顶点的正确投影计算出来。为了实现这个操作，可以复制ShadowCasterPass的代码到我们的pass，也可以定义一个新的顶点函数并且替换#pragma vertex ShadowPassVertex，例如：12345678910111213141516#pragma vertex vert ... // 从ShadowCasterPass复制函数并稍作修改Varyings vert(Attributes input) &#123; Varyings output; UNITY_SETUP_INSTANCE_ID(input); // 置换的示例 input.positionOS += float4(0, _SinTime.y, 0, 0); output.uv = TRANSFORM_TEX(input.texcoord, _BaseMap); output.positionCS = GetShadowPositionHClip(input); return output;&#125; DepthOnly可以用类似的方法处理DepthOnly pass，只有一点点区别：1234567891011121314151617181920212223242526Pass &#123; Name \"DepthOnly\" Tags &#123; \"LightMode\"=\"DepthOnly\" &#125; ZWrite On ColorMask 0 HLSLPROGRAM #pragma prefer_hlslcc gles #pragma exclude_renderers d3d11_9x gles #pragma shader_feature _ALPHATEST_ON #pragma shader_feature _SMOOTHNESS_TEXTURE_ALBEDO_CHANNEL_A #pragma multi_compile_instancing #pragma multi_compile _ DOTS_INSTANCING_ON #pragma vertex DepthOnlyVertex #pragma fragment DepthOnlyFragment #include \"Packages/com.unity.render-pipelines.core/ShaderLibrary/CommonMaterial.hlsl\" #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/SurfaceInput.hlsl\" #include \"Packages/com.unity.render-pipelines.universal/Shaders/DepthOnlyPass.hlsl\" ENDHLSL&#125; DepthOnlyPass.hlsl由URP管线提供，有顶点偏移的操作，则需要复制DepthOnlyVertex函数到我们的着色器中，然后重命名为vert，添加偏移的代码到其中即可。 内置与URP管线差异总结下面总结一下URP管线相比于内置管线在编写着色器时的代码区别，可能会有遗漏。 在Subshader语义块中使用”RenderPipeline”=”UniversalRenderPipeline” URP使用以下”LightMode”标签： UniversalForward - 使用前向渲染器渲染对象 ShadowCaster - 用来投影 DepthOPnly - 用来渲染scene view的深度纹理，在自定义的render feature中可以调用 Meta - 仅用于烘焙光照贴图 Universal2D - 开启2D 渲染器，取代前向渲染器 UniversalGBuffer - 与延迟渲染有关，还在开发中。 URP使用单pass的前向渲染，只有第一个标签为”UniversalForward”的Pass(当前GPU支持的)会用被来渲染物体，所以不能渲染多个同类型标签的Pass。&lt;/font&gt;如果使用无标签的Pass，会破坏SRP Batcher的批处理。所以建议分开使用着色器或材质，用于不同的MeshRenderers或在前向渲染器中使用RenderObjects特性在特定的层使用一个overrideMaterial重新绘制物体。 RenderObjects前向渲染器特性可以用于使用overrideMaterial重绘制对象到指定的层，单属性的值不会被保留，除非使用一个材质属性语义块，但也会破坏SRP的批处理。也可以覆盖stencil和ztest的值。 可以编写自定义的现象渲染特性，例如Blit方法可以实现自定义的后期处理效果。URP后处理目前不包含自定义的效果。 使用HLSLPROGRAM/HLSLINCLUDE和ENHLSL，不使用CG的版本，否则会与URP的ShaderLibrary产生冲突。 包含URP的ShaderLibrary核心库而不是UnityCG.cginc1#include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" 内置管线中与顶点着色器和片元着色器相关的结构体一般命名为appdata和v2f，但URP中的使用习惯是命名为Attributes和Varyings。 为了兼容和支持SRP Batcher，着色器中需要有UnityPerMaterial CBUFFER，并且每个Pass都共享同样的CBUFFER，因此使用HLSLINCLUDE在Subshader中包含该CBUFFER。CBUFFER中包含属性语义块中的所有非纹理参数。例如： 12345678910111213Properties &#123; _BaseMap (\"Example Texture\", 2D) = \"white\" &#123;&#125; _BaseColor (\"Example Colour\", Color) = (0, 0.66, 0.73, 1)&#125;...HLSLINCLUDE #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" CBUFFER_START(UnityPerMaterial) float4 _BaseMap_ST; float4 _BaseColor; CBUFFER_ENDENDHLSL 如果包含SurfaceInput.hlsl并使用其中的函数，那么需要使用_BaseMap代表albedo贴图，而不是使用_MainTex。但后期处理材质还是会使用_MainTex作为颜色输出进行Blit操作。 定义纹理和采样器，使用以下宏：12TEXTURE2D(_BaseMap);SAMPLER(sampler_BaseMap); 使用SAMPLE_TEXTURE2D()采样贴图：1half4 baseMap = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, IN.uv); TRANSFORM_TEX宏也存在于URP管线中。 UnityObjectToClpPos由TransformObjectToHClip取代。当然也可以使用GetVertexPositionInputs获取顶点在各个空间中的坐标，没有被使用到的坐标系不会参与编译。 12345678910111213141516struct Attributes &#123; float4 positionOS : POSITION;&#125;; struct Varyings &#123; float3 positionCS : SV_POSITION; float3 positionWS : TEXCOORD2;&#125;; Varyings vert(Attributes IN) &#123; Varyings OUT; VertexPositionInputs positionInputs = GetVertexPositionInputs(IN.positionOS.xyz); OUT.positionCS = positionInputs.positionCS; OUT.positionWS = positionInputs.positionWS; return OUT;&#125; 与顶点位置类似，使用GetVertexNormalInputs可以获取世界空间的Normal, Tangent和Bitangent向量。如果仅需要世界空间法向量，那么可以使用TransformObjectToWorldNormal()获取。 123VertexNormalInputs normalInputs = GetVertexNormalInputs(IN.normalOS, IN.tangentOS);// 仅需要Normal时使用:OUT.normalWS = TransformObjectToWorldNormal(IN.normalOS) URP不支持Surface Shader，所以需要自己编写vertex/fragment着色器。如果需要支持灯光交互，可以包含Lighting.hlsl，其中含有很多计算光照的函数。 1#include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl\" 如果包含了Lighting.hlsl计算光影，那么下面的一些关键字可能需要被定义，如果某些关键字没有被定义，那么ShaderLibrary会跳过相关的计算步骤： 123456789101112131415161718// 主光源阴影#pragma multi_compile _ _MAIN_LIGHT_SHADOWS#pragma multi_compile _ _MAIN_LIGHT_SHADOWS_CASCADE // 额外灯光和其阴影#pragma multi_compile _ _ADDITIONAL_LIGHTS_VERTEX _ADDITIONAL_LIGHTS#pragma multi_compile _ _ADDITIONAL_LIGHT_SHADOWS // 柔和的阴影#pragma multi_compile _ _SHADOWS_SOFT // 其他(混合光照，烘焙光照贴图，雾)#pragma multi_compile _ _MIXED_LIGHTING_SUBTRACTIVE#pragma multi_compile _ DIRLIGHTMAP_COMBINED#pragma multi_compile _ LIGHTMAP_ON#pragma multi_compile_fog // 支持阴影则须将世界空间的顶点位置信息和ShadowCoord传入片元着色器 使用ComputeFogFactor和MixFog函数处理雾： 123456789101112131415#pragma multi_compile_fog struct Varyings &#123; ... half fogFactor : TEXCOORD5; // 或者其他没有被使用的texcoord // 如果都被占用了，则将其与一个half3合并在一起&#125;... // 顶点着色器:half fogFactor = ComputeFogFactor(positionInputs.positionCS.z); // 片元着色器:color.rgb = MixFog(color.rgb, IN.fogFactor);","categories":[{"name":"Unity","slug":"Unity","permalink":"https://cuihongzhi1991.github.io/categories/Unity/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://cuihongzhi1991.github.io/tags/Unity/"},{"name":"URP","slug":"URP","permalink":"https://cuihongzhi1991.github.io/tags/URP/"},{"name":"材质","slug":"材质","permalink":"https://cuihongzhi1991.github.io/tags/%E6%9D%90%E8%B4%A8/"}]},{"title":"Unity Built-in转URP速查表","slug":"builtinttourp","date":"2020-05-27T12:43:03.000Z","updated":"2020-05-27T14:10:11.616Z","comments":true,"path":"2020/05/27/builtinttourp/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/05/27/builtinttourp/","excerpt":"本篇文章转自Teofilo Dutra编写的《From Built-in to URP》，其中有很多在写URP管线Shader时需要用到的函数，作为备忘速查表非常实用，所以记录于此。本文经过精简和翻译，不一定适用于大家，可以点击上方链接跳转至作者原文。本文是基于7.3版本的URP编写的，有些暂时还不支持的内容可能在后续版本更新迭代。","text":"本篇文章转自Teofilo Dutra编写的《From Built-in to URP》，其中有很多在写URP管线Shader时需要用到的函数，作为备忘速查表非常实用，所以记录于此。本文经过精简和翻译，不一定适用于大家，可以点击上方链接跳转至作者原文。本文是基于7.3版本的URP编写的，有些暂时还不支持的内容可能在后续版本更新迭代。 结构首先要在SubShader的Tags中添加”RenderPipeline” = “UniversalPipeline”，并且使用HLSL的宏代替旧版的CG语言宏。 Built-in URP CGPROGRAM / HLSLPROGRAM HLSLPROGRAM ENDCG / ENDHLSL ENDHLSL CGINCLUDE / HLSLINCLUDE HLSLINCLUDE Include文件的改动 Content Built-in URP Core Unity.cginc Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl Light AutoLight.cginc Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl Shadows AutoLight.cginc Packages/com.unity.render-pipelines.universal/ShaderLibrary/Shadows.hlsl Surface shaders Lighting.cginc 无 其他常用的include文件: Packages/com.unity.render-pipelines.core/ShaderLibrary/SpaceTransforms.hlsl Packages/com.unity.render-pipelines.universal/ShaderLibrary/ShaderVariablesFunctions.hlsl Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl Packages/com.unity.render-pipelines.universal/ShaderLibrary/Input.hlsl Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareOpaqueTextue.hlsl 光照模式 Built-in URP ForwardBase UniversalForward ForwardAdd 无 Deferred and related UniversalGBuffer seems to have just been added to URP Vertex and related 无 ShadowCaster ShadowCaster MotionVectors 暂不支持 URP其他支持的光照模式： DepthOnly Meta (用于烘焙光照贴图) Universal2D 变体(Variants)URP支持着色器的变体，可以使用#pragma multi_compile宏实现编译不同需求下的着色器，常见的内置关键字有： _MAIN_LIGHT_SHADOWS _MAIN_LIGHT_SHADOWS_CASCADE _ADDITIONAL_LIGHTS_VERTEX _ADDITIONAL_LIGHTS _ADDITIONAL_LIGHT_SHADOWS _SHADOWS_SOFT _MIXED_LIGHTING_SUBTRACTIVE 预定义的着色器预处理宏辅助宏(Helpers) Built-in URP UNITY_PROJ_COORD(a) 无，使用 a.xy/a.w 来代替 UNITY_INITIALIZE_OUTPUT(type, name) ZERO_INITIALIZE(type, name) 阴影贴图需要包含 Packages/com.unity.render-pipelines.universal/ShaderLibrary/Shadows.hlsl Built-in URP UNITY_DECLARE_SHADOWMAP(tex) TEXTURE2D_SHADOW_PARAM(textureName, samplerName) UNITY_SAMPLE_SHADOW(tex, uv) SAMPLE_TEXTURE2D_SHADOW(textureName, samplerName, coord3) UNITY_SAMPLE_SHADOW_PROJ(tex, uv) SAMPLE_TEXTURE2D_SHADOW(textureName, samplerName, coord4.xyz/coord4.w) 纹理/采样器的声明宏 Built-in URP UNITY_DECLARE_TEX2D(name) TEXTURE2D(textureName); SAMPLER(samplerName); UNITY_DECLARE_TEX2D_NOSAMPLER(name) TEXTURE2D(textureName); UNITY_DECLARE_TEX2DARRAY(name) TEXTURE2D_ARRAY(textureName); SAMPLER(samplerName); UNITY_SAMPLE_TEX2D(name, uv) SAMPLE_TEXTURE2D(textureName, samplerName, coord2) UNITY_SAMPLE_TEX2D_SAMPLER(name, samplername, uv) SAMPLE_TEXTURE2D(textureName, samplerName, coord2) UNITY_SAMPLE_TEX2DARRAY(name, uv) SAMPLE_TEXTURE2D_ARRAY(textureName, samplerName, coord2, index) UNITY_SAMPLE_TEX2DARRAY_LOD(name, uv, lod) SAMPLE_TEXTURE2D_ARRAY_LOD(textureName, samplerName, coord2, index, lod) 内置的着色器辅助函数可以在 Packages/com.unity.render-pipelines.core/ShaderLibrary/SpaceTransforms.hlsl 看到下方的所有函数 顶点变换函数 Built-in URP float4 UnityObjectToClipPos(float3 pos) float4 TransformObjectToHClip(float3 positionOS) float3 UnityObjectToViewPos(float3 pos) TransformWorldToView(TransformObjectToWorld(positionOS)) 泛用的辅助函数 Built-in URP Include float3 WorldSpaceViewDir (float4 v) float3 GetWorldSpaceViewDir(float3 positionWS) Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/ShaderVariablesFunctions.hlsl” float3 ObjSpaceViewDir (float4 v) 无，使用 TransformWorldToObject(GetCameraPositionWS()) - objectSpacePosition; float2 ParallaxOffset (half h, half height, half3 viewDir) 可能没有，从 UnityCG.cginc 复制 fixed Luminance (fixed3 c) real Luminance(real3 linearRgb) Include “Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl” fixed3 DecodeLightmap (fixed4 color) real3 DecodeLightmap(real4 encodedIlluminance, real4 decodeInstructions) Include “Packages/com.unity.render-pipelines.core/ShaderLibrary/EntityLighting.hlsl” URP中decodeInstructions 为 half4(LIGHTMAP_HDR_MULTIPLIER, LIGHTMAP_HDR_EXPONENT, 0.0h, 0.0h) float4 EncodeFloatRGBA (float v) 可能没有， 从 UnityCG.cginc 复制 float DecodeFloatRGBA (float4 enc) 可能没有， 从 UnityCG.cginc 复制 float2 EncodeFloatRG (float v) 可能没有， 从 UnityCG.cginc 复制 float DecodeFloatRG (float2 enc) 可能没有， 从 UnityCG.cginc 复制 float2 EncodeViewNormalStereo (float3 n) 可能没有， 从 UnityCG.cginc 复制 float3 DecodeViewNormalStereo (float4 enc4) 可能没有， 从 UnityCG.cginc 复制 前向渲染辅助函数 Built-in URP Include float3 WorldSpaceLightDir (float4 v) _MainLightPosition.xyz - TransformObjectToWorld(objectSpacePosition) Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Input.hlsl” float3 ObjSpaceLightDir (float4 v) TransformWorldToObject(_MainLightPosition.xyz) - objectSpacePosition Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Input.hlsl” float3 Shade4PointLights (…) 无，可尝试用half3 VertexLighting(float3 positionWS, half3 normalWS) include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl” 屏幕空间辅助函数 Built-in URP Include float4 ComputeScreenPos (float4 clipPos) float4 ComputeScreenPos(float4 positionCS) Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/ShaderVariablesFunctions.hlsl” float4 ComputeGrabScreenPos (float4 clipPos) 无 顶点光照的辅助函数 Built-in URP Include float3 ShadeVertexLights (float4 vertex, float3 normal) 无，可尝试用 UNITY_LIGHTMODEL_AMBIENT.xyz + VertexLighting(…) include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl” 可以在 Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl 中找到一些通用函数 内置的着色器变量 Built-in URP Include _LightColor0 _MainLightColor Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Input.hlsl” _WorldSpaceLightPos0 _MainLightPosition Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Input.hlsl” _LightMatrix0 可能还不支持 unity_4LightPosX0, unity_4LightPosY0, unity_4LightPosZ0 URP中，额外的灯光存储在一个数组或缓冲中(取决于平台),使用Light GetAdditionalLight(uint i, float3 positionWS)获取光照信息 Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl” unity_4LightAtten0 URP中，额外的灯光存储在一个数组或缓冲中(取决于平台),使用Light GetAdditionalLight(uint i, float3 positionWS)获取光照信息 Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl” unity_LightColor URP中，额外的灯光存储在一个数组或缓冲中(取决于平台),使用Light GetAdditionalLight(uint i, float3 positionWS)获取光照信息 Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl” unity_WorldToShadow float4x4 _MainLightWorldToShadow[MAX_SHADOW_CASCADES + 1] or _AdditionalLightsWorldToShadow[MAX_VISIBLE_LIGHTS] Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Shadows.hlsl” 可以使用GetAdditionalLight(…)获取额外的光源，也可以使用GetAdditionalLightsCount()查询额外的光源数量。 其他方法阴影更多阴影相关函数可以查看 Packages/com.unity.render-pipelines.universal/ShaderLibrary/Shadows.hlsl Built-in URP UNITY_SHADOW_COORDS(x) 可能没有，可以写作float4 shadowCoord : TEXCOORD0; TRANSFER_SHADOW(a) a.shadowCoord = TransformWorldToShadowCoord(worldSpacePosition) SHADOWS_SCREEN 暂不支持 雾更多雾相关的函数可以查看 Packages/com.unity.render-pipelines.universal/ShaderLibrary/ShaderVariablesFunctions.hlsl Built-in URP UNITY_FOG_COORDS(x) 可能没有，可以写作float fogCoord : TEXCOORD0; UNITY_TRANSFER_FOG(o, outpos) o.fogCoord = ComputeFogFactor(clipSpacePosition.z); UNITY_APPLY_FOG(coord, col) color = MixFog(color, i.fogCoord); 深度可以包含 “Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl” 并使用 _CameraDepthTexture来调用深度纹理。也可以使用SampleSceneDepth(…) 和 LoadSceneDepth(…)。 Built-in URP Include LinearEyeDepth(sceneZ) LinearEyeDepth(sceneZ, _ZBufferParams) Include “Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl” Linear01Depth(sceneZ) Linear01Depth(sceneZ, _ZBufferParams) Include “Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl” 其他 Built-in URP Include ShadeSH9(normal) SampleSH(normal) Include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl” unity_ColorSpaceLuminance 无，使用Luminance() Include “Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl” 后期/特效URP不支持OnPreCull, OnPreRender, OnPostRender 和 OnRenderImage. 支持 OnRenderObject 和 OnWillRenderObject。RenderPipelineManager提供了渲染管线中注入的位置： beginCameraRendering(ScriptableRenderContext context, Camera camera) endCameraRendering(ScriptableRenderContext context, Camera camera) beginFrameRendering(ScriptableRenderContext context,Camera[] cameras) endFrameRendering(ScriptableRenderContext context,Camera[] cameras) 例如：1234567891011121314151617181920void OnEnable()&#123; RenderPipelineManager.beginCameraRendering += MyCameraRendering;&#125;void OnDisable()&#123; RenderPipelineManager.beginCameraRendering -= MyCameraRendering;&#125;void MyCameraRendering(ScriptableRenderContext context, Camera camera)&#123; ... if(camera == myEffectCamera) &#123; ... UniversalRenderPipeline.RenderSingleCamera(context, camera); &#125; ...&#125;另外，可以创建ScriptableRendererFeature来实现后期处理效果。可以在管线的不同阶段注入ScriptableRenderPasses： BeforeRendering BeforeRenderingShadows AfterRenderingShadows BeforeRenderingPrepasses AfterRenderingPrePasses BeforeRenderingOpaques AfterRenderingOpaques BeforeRenderingSkybox AfterRenderingSkybox BeforeRenderingTransparents AfterRenderingTransparents BeforeRenderingPostProcessing AfterRenderingPostProcessing AfterRendering 下面是一个示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class CustomRenderPassFeature : ScriptableRendererFeature&#123; class CustomRenderPass : ScriptableRenderPass &#123; CustomRPSettings _CustomRPSettings; RenderTargetHandle _TemporaryColorTexture; private RenderTargetIdentifier _Source; private RenderTargetHandle _Destination; public CustomRenderPass(CustomRPSettings settings) &#123; _CustomRPSettings = settings; &#125; public void Setup(RenderTargetIdentifier source, RenderTargetHandle destination) &#123; _Source = source; _Destination = destination; &#125; public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) &#123; _TemporaryColorTexture.Init(\"_TemporaryColorTexture\"); &#125; public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) &#123; CommandBuffer cmd = CommandBufferPool.Get(\"My Pass\"); if (_Destination == RenderTargetHandle.CameraTarget) &#123; cmd.GetTemporaryRT(_TemporaryColorTexture.id, renderingData.cameraData.cameraTargetDescriptor, FilterMode.Point); cmd.Blit(_Source, _TemporaryColorTexture.Identifier()); cmd.Blit(_TemporaryColorTexture.Identifier(), _Source, _CustomRPSettings.m_Material); &#125; else &#123; cmd.Blit(_Source, _Destination.Identifier(), _CustomRPSettings.m_Material, 0); &#125; context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); &#125; public override void FrameCleanup(CommandBuffer cmd) &#123; if (_Destination == RenderTargetHandle.CameraTarget) &#123; cmd.ReleaseTemporaryRT(_TemporaryColorTexture.id); &#125; &#125; &#125; [System.Serializable] public class CustomRPSettings &#123; public Material m_Material; &#125; public CustomRPSettings m_CustomRPSettings = new CustomRPSettings(); CustomRenderPass _ScriptablePass; public override void Create() &#123; _ScriptablePass = new CustomRenderPass(m_CustomRPSettings); _ScriptablePass.renderPassEvent = RenderPassEvent.AfterRenderingOpaques; &#125; public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) &#123; _ScriptablePass.Setup(renderer.cameraColorTarget, RenderTargetHandle.CameraTarget); renderer.EnqueuePass(_ScriptablePass); &#125;&#125;","categories":[{"name":"Unity","slug":"Unity","permalink":"https://cuihongzhi1991.github.io/categories/Unity/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://cuihongzhi1991.github.io/tags/Unity/"},{"name":"URP","slug":"URP","permalink":"https://cuihongzhi1991.github.io/tags/URP/"}]},{"title":"微积分公式速查表","slug":"calculusequations","date":"2020-05-24T10:06:00.000Z","updated":"2020-05-24T10:11:03.814Z","comments":true,"path":"2020/05/24/calculusequations/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/05/24/calculusequations/","excerpt":"本篇文章汇总了由John Vince编写的《Calculus for Computer Graphics》中推导和总结的绝大部分微积分公式。这本书是基于图形学常用的微积分进行讲解的，所以公式也基本是图形学中常见常用的公式。","text":"本篇文章汇总了由John Vince编写的《Calculus for Computer Graphics》中推导和总结的绝大部分微积分公式。这本书是基于图形学常用的微积分进行讲解的，所以公式也基本是图形学中常见常用的公式。","categories":[{"name":"数学","slug":"数学","permalink":"https://cuihongzhi1991.github.io/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://cuihongzhi1991.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"name":"微积分","slug":"微积分","permalink":"https://cuihongzhi1991.github.io/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/"}]},{"title":"UE4中用球面高斯函数实现移动端SSS效果","slug":"sgsss","date":"2020-05-11T06:14:25.000Z","updated":"2020-05-11T23:53:37.620Z","comments":true,"path":"2020/05/11/sgsss/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/05/11/sgsss/","excerpt":"目前一些移动端的皮肤材质采用的是2011年Eric分享的Pre-integrated Skin Shading的精简版，主要是利用$N\\cdot L$与模型表面的曲率去采样预计算的LUT图，并将结果作为新的NoL来计算漫反射的颜色。但现在很多3D手游的带宽比较吃紧，而ALU占用率不是很高，而且不少手机GPU芯片还在不断增加ALU，那么将采样LUT图的方式转换为纯算术的方式岂不美哉。","text":"目前一些移动端的皮肤材质采用的是2011年Eric分享的Pre-integrated Skin Shading的精简版，主要是利用$N\\cdot L$与模型表面的曲率去采样预计算的LUT图，并将结果作为新的NoL来计算漫反射的颜色。但现在很多3D手游的带宽比较吃紧，而ALU占用率不是很高，而且不少手机GPU芯片还在不断增加ALU，那么将采样LUT图的方式转换为纯算术的方式岂不美哉。 骑手日记五一送外卖的间隙翻到了一篇博文，原文作者Matt是Ready At Down工作室(开发了《教团:1886》)的图形工程师，他简述了一种使用Spherical Gaussian(球面高斯函数，以下简称SG)近似预积分SSS材质的方式。虽然Matt只是抛出一个不完整的思路供大家参考和讨论，但我实际操作后觉得效果还不错。 优点：可以很灵活的制作不同的自定义Diffusion Profile(扩散剖面)，模拟人类皮肤、非人类皮肤或普通的次表面散射皆可；不用采样LUT图，节约带宽。缺点：额外的ALU占用率；没有完整的实时SG SSS实现参考。 下面开始踩坑，错误的地方请各位老板不要给差评，一个差评白跑一天。 Spherical Gaussian参考资料SG是比较冷门的话题，但Ready At Dawn工作室却对其情有独钟，并使用在自研的游戏引擎中，其效果也经《教团：1886》得到验证：2016年Matt在个人博客中编写了6篇关于光照贴图烘焙与SG实际应用的博文。其中很多算法和实现思路都是参考龚大(叛逆者)的论文。我也将重要的前5篇翻译到了自己的博客，感兴趣的老铁可以戳戳。 什么是SG？高斯函数和用于图像处理的二维高斯函数比较常见的，而SG就是三维空间中分布在球面上的高斯函数。一维的高斯函数的形式是：\\begin{align}ae^{\\frac{-(x-b)^{2}}{2c^{2}}} \\nonumber\\end{align} (x-b)项使一维高斯函数在笛卡尔坐标系中可以求出给定点到高斯中心的距离。而三维的球面高斯函数参数与一维和二维的不同，需要改变(x-b)项，让高斯函数根据两个标准化的方向向量夹角进行计算使其作用在球面上。用点积的方式就可以实现：\\begin{align}G(v;\\mu,\\lambda,a) = ae^{\\lambda(\\mu\\cdot{v}-1)}\\nonumber\\end{align} 和普通高斯函数一样，有一些参数可以控制波瓣的形状和位置。参数\\mu是波瓣的轴向或方向，控制波瓣在球面的位置并且指向波瓣的中心；参数\\lambda是波瓣的sharpness(锐度)，增加该值时，波瓣会变得更纤细，也就意味着越是远离波瓣轴衰减的越快；参数a是波瓣的振幅或者强度，是波瓣波峰顶部的高度值，可以是标量值，在图形学中也可以是向量，来控制RGB不同颜色通道的变化。在HLSL代码中，只需要球面上一点的标准化方向向量就可以求出该点的球面高斯值。123456789101112struct SG&#123; float3 Amplitude; // float3或者float皆可，按需求设定 float3 Axis; float Sharpness;&#125;float3 EvaluateSG(in SG sg, in float3 dir)&#123; float cosAngle = dot(dir, sg.Axis); return sg.Amplitude * exp(sg.Sharpness * (cosAngle - 1.0f));&#125; 为何使用SG？SG非常直观易于理解，而且很多论文已经探索了SG的使用价值，并使用SG对材质的漫反射和镜面反射实现了预计算的辐射率传递(pre-computed radiance transfer, PRT)。尤其是龚大的《All-Frequency Rendering of Dynamic, Spatially-Varing Reflectance》一文成为RAD工作室使用球面高斯函数的主要参考和灵感。SG有以下几个特点： 两个SG做积运算可以得到另外一个SG；\\begin{align}G_1(v)G_2(v) = G(v;\\frac{\\mu_m}{||\\mu_m||},a_1a_2e^{\\lambda_m(||\\mu_m||-1)}) \\nonumber\\end{align} 计算整个球面的SG积分可以得到SG的总“能量”，对光照计算很有用；\\begin{align}\\int_{\\Omega}G(v)dv = 2\\pi\\frac{a}{\\lambda}(1-e^{-2\\lambda}) \\nonumber\\end{align} 两个SG也可以做点积运算，求出两个SG乘积的积分。\\begin{align}\\int_{\\Omega}G_1(v)G_2(v)dv = 2\\pi{a_0}{a_1}\\frac{e^{||\\mu_m||-\\lambda_m}-e^{-||\\mu_m||-\\lambda_m}}{||\\mu_m||} \\nonumber\\end{align} 使用SG近似漫反射光照和镜面光照的详细内容可以看Matt的原文或者戳我的博客。 与SSS何干？ SG可以朝向任意方向，也就是\\mu表示的波瓣轴向。这样就可以与场景中的punctual light(精确光源)完美对齐。SG的\\lambda(锐度)参数可以是任意数值，这样可以表示不同的滤波参数，包括很窄的滤波核。SG很好做归一化(球面的SG积分为1)，可以保证能量守恒。两个SG相乘可以得到另一个SG，意味着可以用一个SG作为滤波核，与代表光源的SG进行相乘得到另一个SG，这个SG则代表预积分的光照信息。SG已经有比较好的近似漫反射光照的方式。(SG系列第三篇) Matt给出了下方的代码：12345678910111213141516float3 diffuse = nDotL;if(EnableSSS)&#123; // Represent the diffusion profiles as spherical gaussians SG redKernel = MakeNormalizedSG(lightDir, 1.0f / max(ScatterAmt.x, 0.0001f)); SG greenKernel = MakeNormalizedSG(lightDir, 1.0f / max(ScatterAmt.y, 0.0001f)); SG blueKernel = MakeNormalizedSG(lightDir, 1.0f / max(ScatterAmt.z, 0.0001f)); // Compute the irradiance that would result from convolving a punctual light source // with the SG filtering kernels diffuse = float3(SGIrradianceFitted(redKernel, normal).x, SGIrradianceFitted(greenKernel, normal).x, SGIrradianceFitted(blueKernel, normal).x);&#125;float3 lightingResponse = diffuse * LightIntensity * DiffuseAlbedo * InvPi; 思路是根据光源朝向和红、绿、蓝三种不同的散射强度创建三个SG核，这三个SG滤波核其实就是模拟红绿蓝三种波长的Diffusion Profile。结合2011年Eric的预积分皮肤PPT来看，根据剖面图可以看出红光比绿光和蓝光散射的更远，因此会出现白色——黄色——橙色——红色——黑色的渐变效果。 因此可以用一个float3 ScatterAmt表示散射强度， x分量表示红光，依此类推。而构建SG时，\\lambda参数表示锐度，\\lambda数值越大表示越细长。因此红光的\\lambda值最小，那么可以简单的用$\\frac{1}{ScatterAmt.x}$来表示红光，依此类推。按照Matt原文的描述，首先是归一化的SG核，然后代表轴向的$\\mu$与光源对齐，代表振幅的与光源强度(也可认为是LightColor)相乘。可以推出下面的代码：1234567891011121314// SG KernelFSphericalGaussian MakeNormalizedSG(float3 LightDir, half Sharpness, half3 LightIntensity)&#123; // 归一化的SG SphericalGaussian SG; SG.Axis = float3(0, 1, 0); // 任意方向 SG.Sharpness = Sharpness; // (1 / ScatterAmt.element) SG.Amplitude = SG.Sharpness / ((2 * PI) - (2 * PI) * exp(-2 * SG.Sharpness)); // 归一化处理 // 对齐轴向，乘上光源强度(颜色) SG.Axis = LightDir; SG.Amplitude *= LightIntensity; return SG;&#125; 因此虽然此函数的名字叫MakeNormalizedSG，但其整个球面积分值已经是乘过光源强度的了，不一定是1。当时我认为Matt可能这里有错误，但我还是too yound, too cai了。因为他后面使用了函数SGIrradianceFitted()来近似渲染方程中的$L_i$与cosine项点积的积分，但这个函数是Stephen Hill提出并且针对归一化SG的，Amplitude项并不会参与计算。所以Matt才在最后一行把光源强度加入计算。破案了，MMP坑了我有一会儿，让我有种文章描述前后矛盾的错觉。SGIrradianceFitted()函数在SG系列的第三篇有写到。是一种比较精确的逼近光源SG与余弦波点积做积分的方式。另外两种较粗糙的近似方式可以看那篇文章。1234567891011121314151617181920212223242526272829float3 SGIrradianceFitted(in SG lightingLobe, in float3 normal)&#123; const float muDotN = dot(lightingLobe.Axis, normal); const float lambda = lightingLobe.Sharpness; const float c0 = 0.36f; const float c1 = 1.0f / (4.0f * c0); float eml = exp(-lambda); float em2l = eml * eml; float rl = rcp(lambda); float scale = 1.0f + 2.0f * em2l - rl; float bias = (eml - em2l) * rl - em2l; float x = sqrt(1.0f - scale); float x0 = c0 * muDotN; float x1 = c1 * x; float n = x0 + x1; float y = saturate(muDotN); if(abs(x0) &lt;= x1) y = n * n / x; float result = scale * y + bias; return result;&#125;好的gays，理论暂时告一段落，整活。 UE4中实现移动端的SGSSS添加着色模型为延迟渲染添加着色模型的流程我照着外网学习了一波并记录在博客中。这次是针对移动端添加新的着色模型，相比为延迟渲染管线需要修改的地方比较少。首先打开你辛辛苦苦下载的UE4.24源码，在EngineTypes.h中为EMaterialShadingModel添加枚举成员，DisplayName材质编辑器UI中的名称。 然后在MaterialShader.cpp中添加着色模型的名称，该名称是在源码内使用的(非UI)： 然后修改HLSLMaterialTranslator.h，编译着色器时为SGSSS添加类型描述宏： 我们将会需要两个材质引脚——Scatter Amount(三维向量)和Curvature(标量，后面会用到)。为了不影响其他引脚的正常使用，我们选择Subsurface和Custom0引脚作为这两个参数的输入接口。在Material.cpp中做修改： 然后在MaterialGraph.cpp中修改引脚的名字，更加直观清晰： 一切搞定， 了吗？并没有。UE4在编译着色器时会检查冗余和不支持的内容然后丢弃掉或者使用默认值替代。在HLSLMaterialTranslator.h中有这么一段代码： 会通过IsSubsurfaceShadingModel()函数来检查你选择的着色模型是否属于Subsurface类，不是的话就不会编译该引脚的输入，那不是白搞事了？所以打开MaterialShared.h，为Subsurface类添加SGSSS： 这是耽误我送外卖的坑点之一。老板们，C++源码部分修改已经完事儿，编译走起来。 编写着色器与延迟渲染管线比，移动端几乎不用修改.ush和.usf就可以取到值，当然这和GBuffer存储数据和提取数据有关。在开始编写代码前，建议开启着色器开发模型，可以自动报错方便调试。位置\\Engine\\Config\\ConsoleVariables.ini。 首先添加一些与SG有关的函数，然而巧的是UE4已经使用龚大的SG算法来计算Bent Normal了，所以有些函数直接用就可以了。在SphericalGaussian.ush文件中，struct FSpherical Gaussian{}是SG的结构体，其中的Axis, Sharpness和Amplitude分别对应的是$ \\mu, \\lambda和a$;DotCosineLobe()其实就是Stephen Hill提出的SGIrradianceFitted()。 下面添加一个MakeNormalizedSG()函数创建归一化的SG，并且轴向为光源方向，锐度是$\\frac{1}{ScatterAmt.element}$： 然后添加计算光照项与Cosine项的函数SGDiffuseLighting() 为了方便测试效果，下面先针对平行光的交互添加代码。在MobileBasePassPixelShader.usf添加头文件： 然后在平行光的渲染部分修改代码，可以看到实现方式类似预积分皮肤的方式，将SG结果作为新的NoL参与计算。 保存.usf文件后，万万不可在UE4工程中按ctrl + shift + .编译所有材质，那成千上万个需要编译的着色器分分钟让你被黑人抬棺。有很多控制台命令可以指定编译路径、文件或材质。我最常用的是recompileshaders material “Material Name”，比如我们创建个材质M_SGSSS，那么后面调试代码的时候每次只需要控制台输入recompileshaders material M_SGSSS即可，只编译此材质就会让黑人抬棺失败。 创建好材质之后，可以调节参数看效果。是不是有预积分内味儿了？ 这个算法目前的瑕疵Eric也提到过，不使用filmic tone mapper的话会看到三色光扩散的范围很明显，用在皮肤上会看到蓝色分离的较明显，我们加上tone mapper对比一下，对比非常明显，经过tone mapping后的非常接近预积分色彩范围(暂时不考虑曲率)。 因为SG制作Diffusion Profile的自由度很高，可以制作各种SSS效果。 如果把同样的算法在点光源和聚光灯的部分实现，然后把一个点光源放到模型里面，效果也很不错。 加入曲率预积分LUT的U方向采样利用的是NoL，我们已经实现了类似的效果。V向采样利用的是曲率。如果不追求较真实合理的效果，不做这一步也是可以的，会得到下面的效果。曲率高的鼻子和眼睛与曲率低的头顶的扩散剖面没区别。 那么按照Eric的方法求出曲率$\\frac{1}{r}$： 如果敢用这种计算出来的曲率绝对被主美打死。 那还是制作一张柔和过度的曲率图吧。如果使用Substance烘焙曲率贴图会发现可调的参数非常少，而且凹面的曲率是0，在鼻翼两侧、下巴、眼窝以及耳朵内部都会变成黑色，结果不正确(也可能我的substance是渣渣)。 于是使用Houdini，好处就是可以先将低面数模型细分一下，然后计算曲率。注意不要用官方提供的Labs中的烘焙贴图工具，那个问题很多且结果不准确。计算后的结果是作为顶点的Cd属性，可以给一个principle shader以顶点色作为base color，最后用bake texture输出出来。对比一下实时计算的效果完胜，缺点是占用带宽，且每个模型都要制作一张图。 曲率越大扩散越强，那么可以尝试将Curvature与ScatterAmt相乘得到新的ScattrerAmt。并且可以在材质中对曲率贴图进行简单的对比度或强度等等方面的操作，这样更加灵活和自由。并且反复调试后我觉得还是不加tone mapper柔和含蓄一点。 又有客户催单了，各位老板慢用，告辞。","categories":[{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"球面高斯","slug":"球面高斯","permalink":"https://cuihongzhi1991.github.io/tags/%E7%90%83%E9%9D%A2%E9%AB%98%E6%96%AF/"},{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"次表面散射","slug":"次表面散射","permalink":"https://cuihongzhi1991.github.io/tags/%E6%AC%A1%E8%A1%A8%E9%9D%A2%E6%95%A3%E5%B0%84/"},{"name":"角色","slug":"角色","permalink":"https://cuihongzhi1991.github.io/tags/%E8%A7%92%E8%89%B2/"}]},{"title":"球面高斯函数05——用球面高斯函数近似辐射率和辐射度","slug":"sg05","date":"2020-05-05T06:14:25.000Z","updated":"2020-05-05T05:18:02.483Z","comments":true,"path":"2020/05/05/sg05/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/05/05/sg05/","excerpt":"这是本系列最后一篇笔记。前两篇讨论了如何在使用球面高斯光源时近似出漫反射和镜面反射。但依然没有说明为什么要使用球面高斯光源照亮场景。回顾本系列第一篇的内容，讨论的是如何将预计算的辐射率和辐射度存储在光照贴图或探针网格中。这也是最后一篇要讨论的主题。","text":"这是本系列最后一篇笔记。前两篇讨论了如何在使用球面高斯光源时近似出漫反射和镜面反射。但依然没有说明为什么要使用球面高斯光源照亮场景。回顾本系列第一篇的内容，讨论的是如何将预计算的辐射率和辐射度存储在光照贴图或探针网格中。这也是最后一篇要讨论的主题。 本系列的其他文章可以点击下方链接跳转。 Part1-光照贴图简史Part2-球面高斯函数101Part3-球面高斯光源的漫射照明Part4-球面高斯光源的镜面高光Part5-用球面高斯函数近似辐射率和辐射度 寻找最佳匹配度数学(尤其是统计学)中的一个常见过程就是获取一组数据点，尝试找出某种可以表示数据的分析曲线，这个过程被称为曲线拟合。也可以认为是一种有损压缩，因为几百个数据点可能需要上千字节的数据，但如果用曲线去近似可能只需要存储几个字节。下图是维基百科的一个示例，图像中有一堆需要去拟合的点，这些数据点来自于正弦波，但实际上可能是各种各样的形式。下方的公式分别对应红线，绿线，橙线和蓝线。 \\begin{align} y = c_0 + c_1 \\cdot x \\nonumber \\end{align}\\begin{align} y = c_0 + c_1 \\cdot x + c_2 \\cdot x^2 \\nonumber \\end{align}\\begin{align} y = c_0 + c_1 \\cdot x + c_2 \\cdot x^2 + c_3 \\cdot x^3 \\nonumber \\end{align}\\begin{align} y = c_0 + c_1 \\cdot x + c_2 \\cdot x^2 + c_3 \\cdot x^3 + c_4\\cdot x^4\\nonumber \\end{align}从上图可以看出更复杂的公式可以形成更复杂的曲线，但需要更多的系数，需要存储更多的数据，并意味着拟合过程更加困难或开销越大。用于拟合的常见技术之一是最小二乘法，将拟合曲线和原始数据差异的总和进行最小化。 另外可以发现最终的拟合曲线其实是多个基函数的线性组合，如$x,x^2,x^3$等。其实可以使用其他的基函数来代替，比如高斯函数！同多项式一样，高斯的总和可以用少数几个系数表示更复杂的函数。例如，根据一些点使用最小二乘法拟合不同数量的高斯函数,下图左显示了一个高斯拟合，图中为两个高斯拟合，图右是三个高斯拟合。 不难发现，添加更多高斯函数时，拟合的结果更接近原始数据。 球面拟合这种拟合数据的方式不仅可以作用于一维的数据集，也可以是多维度的。例如在一个由2维球面坐标系定义的球面上有一些随机方向的样本。假设这些样板代表在该方向上无限狭窄的入射光。如果对这些数据进行最小二乘法，则得到N个球面高斯，它们相加之和可以作为球面上任意方向上辐射率的近似值。只需要拟合算法可以得出每个球面高斯的轴向，振幅和锐度，或者提前固定一些球面高斯的参数值，然后仅拟合其余参数。与庞大的辐射率样本相比，一组球面高斯系数占用的存储空间是非常少的。但如果仅使用几个球面高斯函数，得到的近似值相比原始数据会丢失很多细节。但这与球谐函数等其他存储辐射率或辐射度近似值的方式没有什么区别。下图使用HDR环境贴图作为输入数据，分别用12个和24个球面高斯做最小二乘法拟合之后的结果。 要注意的是，该拟合值作用于球面高斯的振幅上，轴向和锐度是基于球面高斯的数量提前确定好的。求解单个参数允许使用线性最小二乘法，同时拟合所有参数需要使用复杂和开销大的非线性最小二乘法。求解较少的参数降低了存储成本，因为每个探针只需要存储振幅，轴向和锐度可以用全局的常量控制。当然，增加波瓣的数量会增加复杂性和清晰度，会保留原始图像更多的高频细节。 负数球谐函数多项式中使用了负系数所以会有“Ringing”效果，球面高斯也有类似问题。上图中的球面右下角有过暗的区域。最小二乘法为了减少拟合的误差，某些波瓣返回了负系数。假如是一维的情况，有一个连续性很差的点集。用最小二乘法使两个高斯波瓣去拟合，情况如下。 优化过程中，第一个波瓣的振幅为正，第二个波瓣的振幅为负。这就导致了最终会有过暗的区域。第一篇笔记中有提到过球谐函数的类似情况以及解决办法。 那么我们需要给最小二乘法加上约束保证返回正系数。好在已经有了名为非负最小二乘法(non-negative least squares, NNLS)。如果使用该方法用球面高斯拟合原始的辐射率，那么结果会自然和正确很多。下图是HDR环境贴图、12个和24个球面高斯使用NNLS拟合之后的结果。 虽然右下角的明暗趋于正常了，但代价是相比原来的方式，近似的结果更加的模糊。 辐射度比较下面使用不同方式近似辐射率，使用辐射率直接计算出兰伯特漫反射光照的辐射度并比较它们的结果。 除了Ambient Cubemap，其他的近似值都很好。但该HDR环境贴图的照明比较柔和，不容易看出问题，下面使用明暗变化比较极端的HDR环境贴图进行比较。 这次的差异就比较明显了。有大面积的明亮光源的情况，球面高斯的效果更胜一筹，尤其是NNLS版本的12个球面高斯。 因为波瓣方向和锐度都是固定值，那么只需要储存振幅的数据即可。即12个球面高斯波瓣的存储成本等于12组RGB系数(总共36个浮点数)。L2的球谐函数需要9组RGB系数(27个浮点数)。环境立方体贴图仅需要6组RGB系数，仅为球面高斯的一半，所以使用球面高斯需要更多存储空间。然而换个角度，这也是球面高斯的优点。立方体贴图只能使用6个波瓣，职业才可以保持正交性；而球面高斯可以根据质量、性能和存储成本使用任意数量的波瓣。 半球拟合因为实际烘焙光照时，样本点存在于模型表面，所以有一半的球体是位于模型背面的，计算这部分是毫无意义的。我们只需要对模型表面的半球部分做光照的预计算然后存储起来即可。而对于球面高斯来说是很好修改的，只需要求解位于围绕面法线的上半球内的波瓣即可。 采样整个场景为光照贴图每个纹素生成辐射率的近似值，最好的方式是使用光线追踪器(ray tracer)，使用诸如路径跟踪(path tracing)之类的算法来计算特定光线的入射辐射率。下图展示了一个场景的光照贴图的可视化效果，为光照贴图每个纹素生成半球辐射率探针，每个探针使用9个围绕面法线朝向的球面高斯。 镜面反射上篇文章介绍了如何从球面高斯光源计算出镜面反射项。那么在近似入射辐射率方面使用该方式。可以计算出整个场景镜面反射的近似效果。数量较少的波瓣只能应对粗糙度较高的材质，因为球面高斯对入射辐射率的近似不能捕获环境的高频细节。下图是粗糙度为0.25的GGX分布项的测试场景。 与真实的效果相比，球面高斯在某些地方的近似不错，在某些地方的近似差一些。但总体来说比L2的球谐函数结果好不少，而且存储成本相同(27个浮点数)。球谐函数使用3D查找纹理存储预计算的球谐系数，如果仔细观察垂直相机的墙面就可以看到插值导致的瑕疵。 《教团:1886》中的实现对于场景中的静态网格体，在2D光照贴图中储存5-12个轴向和锐度值固定的球面高斯波瓣。对于动态的网格体，会提前烘焙包含球形探针的3D Grid到3D纹理中，每个探针有9个球面高斯波瓣。3D Grid是由灯光艺术家在场景中手动摆放的。然后在计算每个像素的光照前，利用硬件的纹理过滤在相邻的探针间做插值。 早期的测试是用CPU烘焙的，但最终使用的是CUDA烘焙工具做GPU烘焙，将计算结果投影到球面高斯波瓣上。下图比较了计算球面高斯波瓣计算的辐射率近似值。 为了性能和存储考虑，没有使用太多的球面高斯波瓣，这样在粗糙度较低的材质表面就会丢失很多细节。所以最终的方案是基于模型表面材质粗糙度在环境贴图和光照贴图两者中做选择，并在很小的区域内将两者的镜面反射进行混合。","categories":[{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"球面高斯","slug":"球面高斯","permalink":"https://cuihongzhi1991.github.io/tags/%E7%90%83%E9%9D%A2%E9%AB%98%E6%96%AF/"},{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}]},{"title":"球面高斯函数04——球面高斯光源的镜面高光","slug":"sg04","date":"2020-05-04T06:14:25.000Z","updated":"2020-05-05T00:54:29.557Z","comments":true,"path":"2020/05/04/sg04/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/05/04/sg04/","excerpt":"上篇文章中，讨论了使用漫反射BRDF时如何计算球面高斯光源的分布。下面可以讨论如何计算与视角有关的更复杂的BRDF，这样就可以得到高光的分布。本文会介绍如何逼近基于微表面的镜面反射BRDF对球面高斯光源的反应情况，并且会介绍各向异性球面高斯的概念。","text":"上篇文章中，讨论了使用漫反射BRDF时如何计算球面高斯光源的分布。下面可以讨论如何计算与视角有关的更复杂的BRDF，这样就可以得到高光的分布。本文会介绍如何逼近基于微表面的镜面反射BRDF对球面高斯光源的反应情况，并且会介绍各向异性球面高斯的概念。 本系列的其他文章可以点击下方链接跳转。 Part1-光照贴图简史Part2-球面高斯函数101Part3-球面高斯光源的漫射照明Part4-球面高斯光源的镜面高光Part5-用球面高斯函数近似辐射率和辐射度 微平面镜面反射迪士尼提出的基于物理的渲染公式是当下实时渲染领域比较流行，应用最广的。其中基于微平面的镜面反射BRDF如下： \\begin{align} f(i,o)=\\frac{F(o,h)G(i,o,h)D(h)}{4(n\\cdot{i})(n\\cdot{o})} \\nonumber \\end{align}D项通常称为法线分布函数(Normal Distribution Function, NDF)，描述微面元法线分布的概率，即正确朝向的法线的浓度。可以在粗糙度上做参数化，描述微平面的凹凸程度。低粗糙度会产生锐利清晰的镜面反射和狭窄细长的镜面波瓣；高粗糙度会产生更宽的镜面波瓣。大多数的现代游戏(包括教团:1886)的D项都用的GGX(Trowbridge-Reitz)分布。下面两图都使用的GGX分布，分别使用0.5的粗糙度和0.1的粗糙度；X轴是表面法线和半角向量的夹角。 G项是几何函数(Geometry Function)，也被称为掩蔽阴影函数(Masking-Shadow Function)。描述微平面自成阴影的属性，即微面元法线与面法线一致并未被遮蔽的表面点的百分比。下图使用的是Smith-GGX函数作为G项的曲线，粗糙度为0.25，法线与视线夹角为0。 F项是菲涅尔方程(Fresnel Equation)，描述不同的表面角下表面所反射的光线所占的比率。从F0到F90，反射强度逐渐增加。使用Schilick近似表示菲涅尔项的曲线如下，F0=0.04： 球面高斯光源的镜面反射沿用迪士尼的镜面反射BRDF，为了与精确光源以及IBL探针正常交互。但会按照球面高斯光源对其拓展： \\begin{align} L_o(0,x) = \\int_{\\Omega}\\frac{F(o,h)G(i,o,h)D(h)G_l(i;\\mu,\\lambda,a)cos(\\theta_i)d\\Omega}{4cos(\\theta_i)cos(\\theta_o)} \\nonumber \\end{align}\\begin{align} L_o(0,x) = \\int_{\\Omega}\\frac{F(o,h)G(i,o,h)D(h)ae^{\\lambda(\\mu\\cdot{i}-1)}d\\Omega}{4cos(\\theta_o)} \\nonumber \\end{align}与漫反射不同，现在积分中有多个项与视角有关。那么需要做一些激进的优化得到期望的结果。 D项D项是镜面反射BRDF中最重要的项。该分布决定了镜面高光整体的形状和强度，如果回看GGX曲线，其走势类似于高斯曲线，但不完全匹配。用单个球面高斯是不能实现紧凑高光和长拖尾的的特征。可以把多个高斯相加去逼近，但本文会用简单的单波瓣去近似。《All-Frequency Rendering of Dynamic, Spatially-Varying Reflectance》中提出过一种逼近Cook-Torrance D项的一个简单公式： \\begin{align} D(h) = e^{-(arccos(h\\cdot n)/m)^{2}} \\approx G(h;n,\\frac{2}{m^2},l) \\nonumber \\end{align}但该高斯模型的峰值并不会随着粗糙度变化而变化，好在有简单的分析公式可以计算球面高斯的积分，因此可以将整个积分的幅度值设置为1，这样一个归一化的D项就是： \\begin{align} D_{SG}(h) = G(h;n,\\frac{2}{m^2},\\frac{1}{\\pi m^2}) \\nonumber \\end{align}12345678910SG DistributionTermSG(in float3 direction, in float roughness)&#123; SG distribution; distribution.Axis = direction; float m2 = roughness * roughness; distribution.Sharpness = 2 / m2; distribution.Amplitude = 1.0f / (Pi * m2); return distribution;&#125; 下方的图标显示了当前的近似方式与GGX的差距，上图粗糙度为0.25，下图粗糙度为0.5： 域之间的扭曲现在有了球面高斯格式的法线分布函数，但却无法使用。因为我们是在半角向量中定义的分布函数，球面高斯的轴是指向面法线方向的，而且我们使用半角向量作为采样方向。如果要使用球面高斯积运算来获取球面高斯光源下的分布，必须保证分布波瓣和光源在同一个域的。换言之，分布的中心是随着观察角度变化的，因为半角向量会随着观察方向改变。 为了确保分布波瓣在正确的域中，需要对其扭曲来对齐观察方向的BRDF切片。对于微平面的镜面反射BRDF来说，波瓣是围绕视线反射方向大致居中的。下方图表就是GGX的波瓣，蓝线为观察方向，绿线是面法线方向，粉线是视线反射方向。上图视角为0度，下图视角为45度。 《All-Frequency Rendering of Dynamic, Spatially-Varying Reflectance》中提供了一个简单的扭曲算子，可以是分布波瓣围绕视线反射方向旋转，并且根据原始波瓣中心的差异差异调整锐度。 \\begin{align} \\mu_w = 2(o\\cdot \\mu_d)\\mu_d - o \\nonumber \\end{align}\\begin{align} \\lambda_w = \\frac{\\lambda_d}{4|\\mu_d\\cdot o|} \\nonumber \\end{align}\\begin{align} a_w = a_d \\nonumber \\end{align}1234567891011SG WarpDistributionSG(in SG ndf, in float3 view)&#123; SG warp; warp.Axis = reflect(-view, ndf.Axis); warp.Amplitude = ndf.Amplitude; warp.Sharpness = ndf.Sharpness; warp.Sharpness /= (4.0f * max(dot(ndf.Axis, view), 0.0001f)); return warp;&#125; 现在对比一下扭曲后的球面高斯分布项与GGX分布的差异，红色是GGX分布，绿色是球面高斯分布： 形状稍有偏离，但扭曲后的波瓣出现在了正确的位置上。 剩余项的近似剩余的G项和F项和高斯分布相差甚远，所以不能用球面高斯去近似。《All-Frequency Rendering of Dynamic, Spatially-Varying Reflectance》中针对此问题做了一些假设来回避此问题，即这些项的值在整个BRDF波瓣中保持不变，这样就可以把它们从积分中提出来，并仅针对BRDF波瓣的轴向进行评估。这使得BRDF在掠射角仍然有效果。但是随着粗糙度增加，G项和F项会离波瓣中心越远，BRDF波瓣会变宽，误差会变得明显。 \\begin{align} f_{sg}(i,o) = \\frac{F(o,h_w)G(\\mu_w,o,h_w)\\frac{1}{\\pi m^2}e^{\\lambda_w(\\mu_w \\cdot i -1)}}{4(n\\cdot \\mu_w)(n \\cdot o)} \\nonumber \\end{align}\\begin{align} h_w = \\frac{o+\\mu_w}{||o+\\mu_w||} \\nonumber \\end{align}最后是半球积分中与BRDF相乘的余弦项。《All-Frequency Rendering of Dynamic, Spatially-Varying Reflectance》中建议使用球面高斯乘积来得到一个球面高斯，该球面高斯表示球面高斯分布项与钳制余弦波的近似球面高斯相乘的结果。为了降低开销，采用G项与F项的方式，只会在BRDF波瓣的轴的方向评估余弦项。代码如下：123456789101112131415161718192021222324252627282930313233343536373839float GGX_V1(in float m2, in float nDotX)&#123; return 1.0f / (nDotX + sqrt(m2 + (1 - m2) * nDotX * nDotX));&#125; float3 SpecularTermSGWarp(in SG light, in float3 normal, in float roughness, in float3 view, in float3 specAlbedo)&#123; // Create an SG that approximates the NDF. SG ndf = DistributionTermSG(normal, roughness); // Warp the distribution so that our lobe is in the same // domain as the lighting lobe SG warpedNDF = WarpDistributionSG(ndf, view); // Convolve the NDF with the SG light float3 output = SGInnerProduct(warpedNDF, light); // Parameters needed for the visibility float3 warpDir = warpedNDF.Axis; float m2 = roughness * roughness; float nDotL = saturate(dot(normal, warpDir)); float nDotV = saturate(dot(normal, view)); float3 h = normalize(warpedNDF.Axis + view); // Visibility term evaluated at the center of // our warped BRDF lobe output *= GGX_V1(m2, nDotL) * GGX_V1(m2, nDotV); // Fresnel evaluated at the center of our warped BRDF lobe float powTerm = pow((1.0f - saturate(dot(warpDir, h))), 5); output *= specAlbedo + (1.0f - specAlbedo) * powTerm; // Cosine term evaluated at the center of the BRDF lobe output *= nDotL; return max(output, 0.0f);&#125; 下图是使用球面高斯光源照亮的场景，并使用上文中所有的镜面反射近似方式后的结果，场景的粗糙度为0.128。 各向异性上图中地板的高光又宽又圆，正常的掠射角观察的高光应该会延伸到较远的地方。所以需要重新检查一下D项。下方的3D示意图分别是观察角度较垂直和较倾斜时GGX分布项情况。不难发现角度趋近垂直时，分布情况类似球面高斯一样镜像对称。而趋近于掠射角时就像右图一样，波瓣开始伸展并且不再镜像对称。伸展的波瓣会呈现拉伸的高光。而我们目前的球面高斯分布项则不无法表示这种非对称性。 好在2013年，一篇名为《Anisotropic Spherical Gaussians》的论文解释了如何扩展球面高斯函数来支持各向异性的波瓣宽度或锐度。定义如下： \\begin{align} G(v;[\\mu_x, \\mu_y, \\mu_z], [\\lambda_x, \\lambda_y],a) = a\\cdot S(v,\\mu_z)e^{-\\lambda_x(v\\cdot \\mu_x)-\\lambda_y(v\\cdot \\mu_y)} \\nonumber \\end{align}球面高斯有一个轴，而各向异性球面高斯由$\\mu_x, \\mu_y, \\mu_z$组成了完整的正交基向量。并且各向异性球面高斯有两个锐度参数$\\lambda_x, \\lambda_y$，它们分别控制相对于$\\mu_x$和$\\mu_y$的锐度。例如设置$\\lambda_x$为16，$\\lambda_y$为64，那么拉伸的高斯波瓣就会在$\\lambda_y$方向上更狭窄，并且中心落在$\\mu_z$。下面使用这些参数将各向异性球面高斯显示在球面上： HLSL实现如下：12345678910111213141516171819struct ASG&#123; float3 Amplitude; float3 BasisZ; float3 BasisX; float3 BasisY; float SharpnessX; float SharpnessY;&#125;; float3 EvaluateASG(in ASG asg, in float3 dir)&#123; float sTerm = saturate(dot(asg.BasisZ, dir)); float lambdaTerm = asg.SharpnessX * dot(dir, asg.BasisX) * dot(dir, asg.BasisX); float muTerm = asg.SharpnessY * dot(dir, asg.BasisY) * dot(dir, asg.BasisY); return asg.Amplitude * sTerm* exp(-lambdaTerm - muTerm);&#125; 这篇各向异性球面高斯的论文还提供了两个公式，可用于提高球面高斯光源的镜面反射质量。第一个是新的扭曲算子，可以用NDF作为各向同性球面高斯，然后沿着视线方向拉伸产生比实际BRDF更好的各向异性球面高斯。另一个有用的公式是将各向异性球面高斯与各向同性球面高斯做卷积。可以用来将各向异性扭曲的NDF波瓣与球面高斯光源波瓣做卷积。下图左是球面扭曲，图中是各向异性扭曲，图右是实际的GGX分布。 各向异性的分布看起来更接近实际的GGX NDF分布，因为有了之前缺少的垂直拉伸。下面是HLSL中的实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879float3 ConvolveASG_SG(in ASG asg, in SG sg) &#123; // The ASG paper specifes an isotropic SG as // exp(2 * nu * (dot(v, axis) - 1)), // so we must divide our SG sharpness by 2 in order // to get the nup parameter expected by the ASG formula float nu = sg.Sharpness * 0.5f; ASG convolveASG; convolveASG.BasisX = asg.BasisX; convolveASG.BasisY = asg.BasisY; convolveASG.BasisZ = asg.BasisZ; convolveASG.SharpnessX = (nu * asg.SharpnessX) / (nu + asg.SharpnessX); convolveASG.SharpnessY = (nu * asg.SharpnessY) / (nu + asg.SharpnessY); convolveASG.Amplitude = Pi / sqrt((nu + asg.SharpnessX) * (nu + asg.SharpnessY)); float3 asgResult = EvaluateASG(convolveASG, sg.Axis); return asgResult * sg.Amplitude * asg.Amplitude;&#125; ASG WarpDistributionASG(in SG ndf, in float3 view)&#123; ASG warp; // Generate any orthonormal basis with Z pointing in the // direction of the reflected view vector warp.BasisZ = reflect(-view, ndf.Axis); warp.BasisX = normalize(cross(ndf.Axis, warp.BasisZ)); warp.BasisY = normalize(cross(warp.BasisZ, warp.BasisX)); float dotDirO = max(dot(view, ndf.Axis), 0.0001f); // Second derivative of the sharpness with respect to how // far we are from basis Axis direction warp.SharpnessX = ndf.Sharpness / (8.0f * dotDirO * dotDirO); warp.SharpnessY = ndf.Sharpness / 8.0f; warp.Amplitude = ndf.Amplitude; return warp;&#125; float3 SpecularTermASGWarp(in SG light, in float3 normal, in float roughness, in float3 view, in float3 specAlbedo)&#123; // Create an SG that approximates the NDF SG ndf = DistributionTermSG(normal, roughness); // Apply a warpring operation that will bring the SG from // the half-angle domain the the the lighting domain. ASG warpedNDF = WarpDistributionASG(ndf, view); // Convolve the NDF with the light float3 output = ConvolveASG_SG(warpedNDF, light); // Parameters needed for evaluating the visibility term float3 warpDir = warpedNDF.BasisZ; float m2 = roughness * roughness; float nDotL = saturate(dot(normal, warpDir)); float nDotV = saturate(dot(normal, view)); float3 h = normalize(warpDir + view); // Visibility term output *= GGX_V1(m2, nDotL) * GGX_V1(m2, nDotV); // Fresnel float powTerm = pow((1.0f - saturate(dot(warpDir, h))), 5); output *= specAlbedo + (1.0f - specAlbedo) * powTerm; // Cosine term output *= nDotL; return max(output, 0.0f);&#125; 使用各向异性扭曲后的高光效果看起来好了很多。","categories":[{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"球面高斯","slug":"球面高斯","permalink":"https://cuihongzhi1991.github.io/tags/%E7%90%83%E9%9D%A2%E9%AB%98%E6%96%AF/"},{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}]},{"title":"球面高斯函数03——球面高斯光源的漫射照明","slug":"sg03","date":"2020-05-03T06:14:25.000Z","updated":"2020-05-05T00:54:35.843Z","comments":true,"path":"2020/05/03/sg03/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/05/03/sg03/","excerpt":"本篇是球面高斯函数与预计算光照系列的第三部分，上篇文章提到了球面高斯函数的一些属性，本文会讨论如何在渲染场景中使用这些属性并发挥它们的优势。","text":"本篇是球面高斯函数与预计算光照系列的第三部分，上篇文章提到了球面高斯函数的一些属性，本文会讨论如何在渲染场景中使用这些属性并发挥它们的优势。 本系列的其他文章可以点击下方链接跳转。 Part1-光照贴图简史Part2-球面高斯函数101Part3-球面高斯光源的漫射照明Part4-球面高斯光源的镜面高光Part5-用球面高斯函数近似辐射率和辐射度 天降高斯假设表面的一个点x被光源L照亮，该光源由名为$G_L$的球面高斯函数表示。那么使用兰伯特漫反射BRDF计算出射光辐射率就是下方的公式： \\begin{align} L_o(o,x) = \\int_{\\Omega}{}f(i,o,x)\\cdot L_i(i,x)\\cdot\\cos(\\theta_i)\\cdot{d}\\Omega \\nonumber \\end{align}对于精确光源来讲，本质上就是按比例缩放的三角函数，计算起来像$N\\cdot{L}$一样简单。但如果使用区域光就会遇到麻烦，因为该积分没有闭式解。假设有一个奇特的高斯光源，它的角衰减可以由球面高斯函数精确地表示。如果在渲染公式中将高斯光源作为$L_i$，那么就是一个球面高斯函数与被限制范围(0-1)的余弦波做点积。上篇文章中提到过两个球面高斯做积运算的过程，那么不妨尝试将余弦波拟合成一个球面高斯函数，这样渲染公式中就是将两个球面高斯函数乘积的结果做积分了。根据Jiaping Wang等人的论文《All-Frequency Rendering of Dynamic, Spatially-Varing Reflectance》中的方法，将余弦波拟合到单个球面高斯函数时，$\\lambda$=2.133，a=1.17。代码中的实现就会变成：1234567891011121314151617181920212223SG CosineLobeSG(in float3 direction)&#123; SG cosineLobe; cosineLobe.Axis = direction; cosineLobe.Sharpness = 2.133f; cosineLobe.Amplitude = 1.17f; return cosineLobe;&#125; float3 SGIrradianceInnerProduct(in SG lightingLobe, in float3 normal)&#123; SG cosineLobe = CosineLobeSG(normal); return max(SGInnerProduct(lightingLobe, cosineLobe), 0.0f);&#125; float3 SGDiffuseInnerProduct(in SG lightingLobe, in float3 normal, in float3 albedo)&#123; float3 brdf = albedo / Pi; return SGIrradianceInnerProduct(lightingLobe, normal) * brdf;&#125; 误差分析毕竟是余弦波的近似值，肯定会有误差。最好的办法就是对比两者的曲线： 仅从图表上看，球面高斯显然与余弦波不太匹配。首先，波峰值超过了1，但必须确保曲线下方的面积与余弦波瓣尽量保持一致否则会导致能量损失。另外，球面高斯在球面上的任何地方的值都没有达到0，所以有很长的拖尾。这就意味着当逼近余弦波的球面高斯与精确光源进行积分时，光照会包裹整个球体，超过了N·L等于0的点。不过这种情况与球谐函数有类似之处，球谐函数也超过了$\\frac{\\pi}{2}$的位置，如下图所示： 使用球谐函数的情况下，近似值其实已经是负值了，或许比球面高斯的长拖尾更糟糕。L1球谐函数的近似值很差，L2球谐的近似值效果尚可。下图从左至右：振幅0-1的余弦波，逼近余弦波的球面高斯函数，L2球谐函数。 下面再看一下与球面高斯光源做计算得到漫反射光照的结果。蓝线代表双球面高斯做点积(球面高斯光源与逼近余弦波的球面高斯)。与之对比的是brute-froce数值积分求出的球面高斯与(振幅0-1)的余弦波的乘积。如图所示(球面高斯光源锐度=4.0)： 误差来自于对(振幅0-1)余弦波的近似球面高斯，而不是两个球面高斯点积的过程。最终辐射度的区别不是特别大，明显的区别就是背光区域，由双球面高斯点积的长拖尾导致的。下图使用锐度4.0的球面高斯光源，左为蒙特卡洛重要性采样计算的辐射度，右为与逼近余弦的球面高斯点积所得到的辐射度。 开销更低的近似方式上篇文章提到过球面高斯的另外一个优点——波瓣绕轴对称，并且也讨论过如何计算球面的球面高斯积分从而获得总能量。那么可以尝试从积分中提出一些项，仅对球面高斯的轴朝向做计算。这必然会引入一些误差，但如果提出的项比较平滑，那误差还是可以接受的。公式的变化如下： \\begin{align} L_o(o,x) = \\frac{C_{diffuse}}{\\pi}\\int_{\\Omega}{}G_L(i;\\mu,\\lambda,a)\\cos(\\theta_i){d}\\Omega \\nonumber \\end{align}\\begin{align} L_o(o,x) \\approx \\cos(\\theta_\\mu)\\frac{C_{diffuse}}{\\pi}\\int_{\\Omega}{}G_L(i;\\mu,\\lambda,a){d}\\Omega \\nonumber \\end{align}HLSL代码如下：12345678910111213float3 SGIrradiancePunctual(in SG lightingLobe, in float3 normal)&#123; float cosineTerm = saturate(dot(lightingLobe.Axis, normal)); return cosineTerm * 2.0f * Pi * (lightingLobe.Amplitude) / lightingLobe.Sharpness;&#125; float3 SGDiffusePunctual(in SG lightingLobe, in float3 normal, in float3 albedo)&#123; float3 brdf = albedo / Pi; return SGIrradiancePunctual(lightingLobe, normal) * brdf;&#125; 如果将这种近似方式以曲线形式和之前的作比较，会看出较大的差别。 可以发现绿线代表的是开销较低的近似方式，而曲线的走势是限制范围的余弦波的缩放版本。但是这种近似方式开销非常低，已经将球面高斯函数转成了点光源。 更精确的近似Stephen Hill提出了一种与球面高斯和余弦波积分匹配度非常高的近似方式。他的实现是针对归一化的球面高斯的，但是我们可以计算积分并缩放得到我们需要的结果。1234567891011121314151617181920212223242526272829float3 SGIrradianceFitted(in SG lightingLobe, in float3 normal)&#123; const float muDotN = dot(lightingLobe.Axis, normal); const float lambda = lightingLobe.Sharpness; const float c0 = 0.36f; const float c1 = 1.0f / (4.0f * c0); float eml = exp(-lambda); float em2l = eml * eml; float rl = rcp(lambda); float scale = 1.0f + 2.0f * em2l - rl; float bias = (eml - em2l) * rl - em2l; float x = sqrt(1.0f - scale); float x0 = c0 * muDotN; float x1 = c1 * x; float n = x0 + x1; float y = saturate(muDotN); if(abs(x0) &lt;= x1) y = n * n / x; float result = scale * y + bias; return result * ApproximateSGIntegral(lightingLobe);&#125; 其结果非常接近实际情况，并且可能开销比两个球面高斯点积更低。 在球体上对比结果——左侧是两个球面高斯点积，中间是蒙特卡洛重要性采样所得结果，右侧是Stephen Hill的近似方式。","categories":[{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"球面高斯","slug":"球面高斯","permalink":"https://cuihongzhi1991.github.io/tags/%E7%90%83%E9%9D%A2%E9%AB%98%E6%96%AF/"},{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}]},{"title":"球面高斯函数02——球面高斯函数101","slug":"sg02","date":"2020-05-02T06:14:25.000Z","updated":"2020-05-08T23:37:26.806Z","comments":true,"path":"2020/05/02/sg02/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/05/02/sg02/","excerpt":"本篇是球面高斯函数与预计算光照系列的第二部分，会介绍球面高斯的基础知识——球形径向基函数(spherical radial basis function, SRBF)。本文会介绍一些核心概念，后续的几篇文章会使用这些概念来计算光照贴图或探针中存储的入射光辐射率近似值。","text":"本篇是球面高斯函数与预计算光照系列的第二部分，会介绍球面高斯的基础知识——球形径向基函数(spherical radial basis function, SRBF)。本文会介绍一些核心概念，后续的几篇文章会使用这些概念来计算光照贴图或探针中存储的入射光辐射率近似值。 本系列的其他文章可以点击下方链接跳转。 Part1-光照贴图简史Part2-球面高斯函数101Part3-球面高斯光源的漫射照明Part4-球面高斯光源的镜面高光Part5-用球面高斯函数近似辐射率和辐射度 何为球面高斯函数？球面高斯函数，本质上是定义在球体表面的高斯分布函数。1D的高斯函数就是以e为底的指数函数，下图是以x=0为中心，高度为3的1D高斯函数。 在做图像模糊处理时，也曾听说或使用过高斯模糊，其本质就是使用2D的高斯函数作为滤波器。下图是高斯滤波器应用在2D图像上的白点时的效果。 分布在球面上的高斯函数也是同样的原理，只是维度有了提升，下面是球面高斯示意图。 1D的高斯函数是以下的形式： \\begin{align} ae^{\\frac{-(x-b)^{2}}{2c^{2}}} \\nonumber \\end{align}(x-b)项使1D高斯函数在笛卡尔坐标系中可以求出给定点到高斯中心的距离。而3D的球面高斯函数参数与1D和2D的不同，需要改变(x-b)项，让高斯函数根据两个单位方向向量夹角进行计算使其作用在球面上。用点积的方式就可以实现： \\begin{align} G(v;\\mu,\\lambda,a) = ae^{\\lambda(\\mu\\cdot{v}-1)}\\nonumber \\end{align}和普通高斯函数一样，有一些参数可以控制波瓣的形状和位置。参数$\\mu$是波瓣的轴向或方向，控制波瓣在球面的位置并且指向波瓣的中心；参数$\\lambda$是波瓣的锐度(sharpness)，增加该值时，波瓣会变得更纤细，也就意味着越是远离波瓣轴衰减的越快；参数a是波瓣的振幅或者强度，是波瓣波峰顶部的高度值，可以是标量值，在图形学中也可以是向量，来控制RGB不同颜色通道的变化。在HLSL代码中，只需要球面上一点的标准化方向向量就可以求出该点的球面高斯值。123456789101112struct SG&#123; float3 Amplitude; float3 Axis; float Sharpness;&#125;float3 EvaluateSG(in SG sg, in float3 dir)&#123; float cosAngle = dot(dir, sg.Axis); return sg.Amplitude * exp(sg.Sharpness * (cosAngle - 1.0f));&#125; 为何使用球面高斯函数？球面高斯函数非常直观易于理解，而且很多论文已经探索了球面高斯的使用价值，并对漫反射和镜面反射材质使用球面高斯函数实现了预计算的辐射率传递(pre-computed radiance transfer, PRT)。尤其是《All-Frequency Rendering of Dynamic, Spatially-Varing Reflectance》一文成为RAD工作室使用球面高斯函数的主要参考和灵感。 积运算对两个高斯函数做积运算可以得到另外一个高斯函数，球面高斯函数也是如此。球面上每个点对两个球面高斯函数进行积运算都会产生另外一个球面高斯函数。实质上就是向量的积运算： \\begin{align} G_1(v)G_2(v) = G(v;\\frac{\\mu_m}{||\\mu_m||},a_1a_2e^{\\lambda_m(||\\mu_m||-1)}) \\nonumber \\end{align}\\begin{align} \\lambda_m = \\lambda_1+\\lambda_2 \\nonumber \\end{align}\\begin{align} \\mu_m = \\frac{\\lambda_1\\mu_1+\\lambda_2\\mu_2}{\\lambda_1+\\lambda_2} \\nonumber \\end{align}HLSL代码如下：123456789101112131415SG SGProduct(in SG x, in SG y)&#123; float3 um = (x.Sharpness * x.Axis + y.Sharpness * y.Axis) / (x.Sharpness + y.Sharpness); float umLength = length(um); float lm = x.Sharpness + y.Sharpness; SG res; res.Axis = um * (1.0f / umLength); res.Sharpness = lm * umLength; res.Amplitude = x.Amplitude * y.Amplitude * exp(lm * (umLength - 1.0f)); return res;&#125; 积分高斯函数还有一个很好的属性——积分具有一个闭式解，也作误差函数。当然球面高斯也是如此，可以对整个球面做球面高斯积分： \\begin{align} \\int_{\\Omega}G(v)dv = 2\\pi\\frac{a}{\\lambda}(1-e^{-2\\lambda}) \\nonumber \\end{align}计算积分可以得到球面高斯的总“能量”，对光照的计算很有用。对球面高斯的归一化处理也十分有用(生成一个积分为1的球面高斯)。归一化的球面高斯可以用来表示概率分布，比如法线分布函数(Normal Distribution Function, NDF)。实际上，归一化的球面高斯函数等效于3D中的冯·米塞斯-费舍尔分布(von Mises-Fisher distribution)。 如果移除指数项，计算球面高斯积分开销会很低。随着球面高斯的锐度增加，$(1-e^{-2\\lambda})$项的值会很快逼近1，所以只要锐度足够高，就可以在很小的误差范围内将该项移除掉。下图是锐度(X轴)增加时$(1-e^{-2\\lambda})$项(Y轴)的数值变化： 在HLSL实现球面高斯积分的准确版本和近似版本：12345678910float3 SGIntegral(in SG sg)&#123; float expTerm = 1.0f - exp(-2.0f * sg.Sharpness); return 2 * Pi * (sg.Amplitude / sg.Sharpness) * expTerm;&#125; float3 ApproximateSGIntegral(in SG sg)&#123; return 2 * Pi * (sg.Amplitude / sg.Sharpness);&#125; 点积如果要使用球面高斯积分公式计算两个球面高斯乘积的积分，就是计算两者的点积，通常定义如下： \\begin{align} \\int_{\\Omega}G_1(v)G_2(v)dv = \\frac{4\\pi{a_0}{a_1}}{e^{\\lambda{m}}}\\frac{sinh(||\\mu_m||)}{||\\mu_m||} \\nonumber \\end{align}为了避免数值上的误差可以用下面的形式： \\begin{align} \\int_{\\Omega}G_1(v)G_2(v)dv = 2\\pi{a_0}{a_1}\\frac{e^{||\\mu_m||-\\lambda_m}-e^{-||\\mu_m||-\\lambda_m}}{||\\mu_m||} \\nonumber \\end{align}HLSL中的实现如下：123456789float3 SGInnerProduct(in SG x, in SG y)&#123; float umLength = length(x.Sharpness * x.Axis + y.Sharpness * y.Axis); float3 expo = exp(umLength - x.Sharpness - y.Sharpness) * x.Amplitude * y.Amplitude; float other = 1.0f - exp(-2.0f * umLength); return (2.0f * Pi * expo * other) / umLength;&#125; 阈值球面高斯函数支持”紧凑$\\epsilon$”，也就是阈值。可以定一个角度，以球面高斯轴的$\\theta$弧度内的点的值都大于$\\epsilon$。如果将其翻转，就可以计算出锐度$\\lambda$，给定弧度$\\theta$和$\\epsilon$，反求锐度的公式如下： \\begin{align} ae^{\\lambda(cos\\theta-1)} = \\epsilon \\nonumber \\end{align}\\begin{align} \\lambda = \\frac{ln(\\epsilon)-ln(a)}{cos\\theta-1} \\nonumber \\end{align}HLSL实现如下：1234float SGSharpnessFromThreshold(in float amplitude, in float epsilon, in float cosTheta)&#123; return (log(epsilon) - log(amplitude)) / (cosTheta - 1.0f);&#125; 旋转最后一个要讨论的是旋转操作。旋转球面高斯函数很简单：只需要把旋转变换应用到球面高斯的轴向量上。旋转变换可以用矩阵、四元数或者其他方式实现。L1以上的球面高斯需要更复杂的变换。","categories":[{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"球面高斯","slug":"球面高斯","permalink":"https://cuihongzhi1991.github.io/tags/%E7%90%83%E9%9D%A2%E9%AB%98%E6%96%AF/"},{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}]},{"title":"球面高斯函数01——光照贴图简史","slug":"sg01","date":"2020-05-01T06:14:25.000Z","updated":"2020-05-05T00:54:43.478Z","comments":true,"path":"2020/05/01/sg01/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/05/01/sg01/","excerpt":"球面高斯函数(Spherical Gaussian, SG)是比较冷门的话题，但Ready At Dawn工作室却对其情有独钟，并使用在自研的游戏引擎中。其效果也经《教团：1886》得到验证。本系列是由Ready At Dawn工作室的首席图形和引擎工程师Matt Pettineo编写在自己的博客。我将该系列的学习笔记记录于此，与大家分享。","text":"球面高斯函数(Spherical Gaussian, SG)是比较冷门的话题，但Ready At Dawn工作室却对其情有独钟，并使用在自研的游戏引擎中。其效果也经《教团：1886》得到验证。本系列是由Ready At Dawn工作室的首席图形和引擎工程师Matt Pettineo编写在自己的博客。我将该系列的学习笔记记录于此，与大家分享。 原作者把球面高斯函数及其应用分为6篇介绍： Part1-光照贴图简史Part2-球面高斯函数101Part3-球面高斯光源的漫射照明Part4-球面高斯光源的镜面高光Part5-用球面高斯函数近似辐射率和辐射度Part6-Baking Lab的使用 最后一部分是他制作的开源的光照贴图烘焙Demo的使用方法，暂且不纳入笔记范围。笔记将记录前五篇的主要内容。作为该系列的第一篇，会简单介绍一下研究球面高斯函数(Spherical Gaussians, SG)时需要的背景资料。重点讨论预烘焙的光照贴图或探针存储了什么信息，以及如何使用这些数据来计算漫反射或镜面反射。 开始前，可以看一下文中用到的术语符号： $L_o$ -指向观察方向的出射光辐射率(radiance)$L_i$ -表面入射点的入射光辐射率o -观察方向(着色器光照计算中一般用V表示)i -光线入射方向(着色器光照计算中一般用L表示)n -表面法向量x -表面上某点的3D坐标$\\int_{\\Omega}$ -半球积分$\\theta_i$ - 表面法线与入射光的夹角角度$\\theta_o$ - 表面法线与出射光的夹角角度$f\\left(\\right)$ -BRDF 早期的方式自从有了彩色的3D游戏，就有了预先计算光照贴图的方法，一直延续到现在(2020年)。原理比较简单：为每个纹素预先计算光照数值，然后在游戏运行时对光照数值进行采样来计算表面的最终效果。虽然原理简单，但细节就比较讲究了。比如将“光照”存储在纹理中到底意味着什么？或者计算的到底是什么值？在最早期，从光照贴图中获取的数值只是简单的与材质的漫反射颜色相乘，然后直接输出颜色到屏幕上。一般我们用以下的渲染公式计算从一个入射点计算出射辐射率： \\begin{align} L_o(o,x) = \\int_{\\Omega}{}f(i,o,x)\\cdot L_i(i,x)\\cdot\\cos(\\theta_i)\\cdot{d}\\Omega \\nonumber \\end{align}暂且不考虑伽马矫正和sRGB转换等等，根据上面的描述，如果用普通的漫反射BRDF项(即$\\frac{C_{diffuse}}{\\pi}$)代替BRDF项，那么就会变成： \\begin{align} L_o(o,x) = \\int_{\\Omega}{} \\frac{C_{diffuse}}{\\pi}\\cdot L_i(i,x)\\cdot\\cos(\\theta_i)\\cdot{d}\\Omega \\nonumber \\end{align}\\begin{align} = \\frac{C_{diffuse}}{\\pi}\\int_{\\Omega}{}L_i(i,x)\\cdot\\cos(\\theta_i)\\cdot{d}\\Omega \\nonumber \\end{align}可以看到将右侧的常量项$\\frac{C_{diffuse}}{\\pi}$提到积分外，这样右侧复杂的积分运算就是预计算(pre-computed)的纹素了，因为光照贴图每个纹素存储的都是单一的固定颜色值，所以可以不用考虑观察方向，在运行时用常量项与每个纹素值相乘就是最终的颜色了。右侧的积分计算的是入射光辐射度，因此光照贴图中存储的就是入射光辐射度。实际上大多数的游戏并没有在运行时应用$\\frac{1}{\\pi}$,因为这是个常数项，为了降低开销可以也将这个常数项预计算在光照贴图中，这样只剩$C_{diffuse}$是在运行时参与计算的。这种情形下，实际存储的就是反射率。换言之，可以认为存储的值是当$C_{diffuse}=1.0$时漫反射的反射率，即具有漫反射BRDF的表面最大出射光辐射率。 法线贴图光照贴图的核心概念之一就是利用空间域中以不同密度存储的数据来重建表面的最终效果。简言之，使用一个纹素密度存储光照贴图，并与不同密度(一般更高)的反射率贴图(albedo map)结合。这样无需计算每个纹素的辐射度积分就可以保留高频细节。但如何让辐射度根据其他纹理贴图(不仅仅是反射率贴图)变化呢？为了满足这种需求，在2000年初法线贴图开始被广泛使用，但仅限于与精确光源(punctual light source)计算时使用。并且法线贴图对光照贴图不起作用，因为光照贴图只存储了辐射度的比例值(标量)，那么相比于直接光照区域，仅有环境光照(ambient lighting)的区域就非常的平整。如下图： 为了让光照贴图与法线贴图正确计算，光照贴图每个纹素不再存储单个标量值，而是辐射度的分布信息。法线贴图包含一定范围的方向分布信息，这些方向一般限制在表面上一个点的法线周围半球内。所以光照贴图存储的辐射度分布信息也是定义在同一个半球内的。V社(Valve)使用自研的Source引擎在《半条命2》中最早使用了这种分布，被称为“辐射度法线贴图”(Radiosity Normal Mapping)。 V社修改了光照贴图烘焙器算法，计算三个值而不是一个值，通过投影辐射度到上图中某一个基向量(basis vector)上得到三个值。游戏运行时，会基于法线贴图中的方向与三个基向量的夹角余弦值来混合光照贴图中的三个值从而得到辐射度值(通过开销很低的点积就可以计算)。这样就可以根据法线贴图中的方向有效地改变辐射度，进而避免了仅有环境光的区域过于平整的问题。 这个方式解决了静态物体的问题，对动态的物体和角色应用预计算的光照依然有问题。一些早期游戏(如《Quake》)用了一些技巧,例如在角色脚部位置采样光照贴图的数值，并使用该数值计算出环境光数值应用到整个模型上。而有些游戏的处理方式更粗糙，只把动态灯光和一个全局的环境光项结合使用。V社使用了更复杂的方法，将半球光照贴图基础扩展成由6个正交基向量形成的球面基础。 基向量与一个单位立方体的六个面朝向重合，V社称之为“环境立方体”。使用他们的基函数(basis functions)将辐射度投影到空间中一点周围的所有方向上(而不是面法线周围的半球上)，动态的模型可以对任意法线方向采样辐射度来计算漫反射光照。这种形式被称为“光照探针”(lighting probe)或简称“探针”(probe)。 镜面反射通过V社提出的方法，可以使用高频的法线贴图与光照贴图进行计算得到漫反射光照。为了让画面更真实，还需要支持更加复杂的BRDF，包括受观察方向影响的镜面反射BRDF。《半条命2》通过预生成(pre-generating)的立方体贴图和手动摆放的探针来处理环境的镜面反射。这在现代游戏中也是十分常见的做法(额外添加了预过滤(pre-filtering)来近似微平面BRDF)。但立方体贴图会占用大量的内存空间，因此限制了镜面反射探针(specular probe)的密度，错误的视差(parallax)或遮挡自然会产生一些问题。下图中，由于错误的视差和遮挡，当使用预过滤的环境贴图计算环境镜面反射(environment specular)时，球的边缘反射了自己导致非常亮！ 因此需要让光照贴图对镜面反射同样有影响。如果模仿漫反射BRDF，将镜面反射BRDF从积分中提出来，BRDF · Integrate(Lighting · cos($\\theta_i$))，而不是原本的Integrate(BRDF · Lighting · cos($\\theta_i$))，那么仅仅在观察方向与光照贴图基向量方向接近的时候才能看到些许镜面反射效果。下方示意图展示了改变公式后的效果。 很明显这是错误的，因为兰伯特漫反射BRDF是常量项，可以从积分中提出来，但镜面反射BRDF是与视线方向有关的，不能从积分中提出来。 球谐函数球谐函数(Spherical Harmonics, SH)是实时图形一种流行的工具，通常作为在离散的探针位置存储间接光照近似值的方式。核心就是在球面上用一系列系数(1个、4个、9个、16个、n*n个)近似出一个关于方向(方向定义在球面上)的分布函数。就像使用一个方向向量从一张立方体贴图上获取特定的值一样。使用低阶的球谐函数只能表示非常低频的信号，下图使用27个系数(RGB每通道9个系数)将HDR图投影到L2球谐函数上。 对于辐射度来讲，低频的球谐函数非常适合。相对于余弦项的入射辐射率积分有效地充当了低通滤波器，非常适合用来与球谐函数去近似辐射度。如果将探针位置或光照贴图的纹素的辐射度投影到球谐函数上，就可以进行球谐查找了(lookup)。通过与系数的点积等一些计算就可以得到球面上任意方向的辐射度。 事实证明，用球谐函数从入射辐照亮度计算辐射度很有用，因为球谐函数表示低频信号是很高效的，在频域中进行简单的乘法就可以完成卷积。在空间域中，与立方体贴图的卷积是$n^{2}$的运算，包含来自辐射率立方体贴图的很多样本。下图为L2球谐函数探针作为漫反射光源照亮的兔子模型。 因此球谐函数是用来近似辐射度的，并且可以在运行时将辐射率转化为辐射度。在探针或光照贴图中存储辐射率的近似值而不是辐射率的近似值(虽然是模糊的版本)，这样的低频信号与镜面反射BRDF的乘积进行积分可以得到镜面反射。如果用球谐函数近似辐射度，那么也需要用球谐函数近似BRDF。 然而基于微平面理论的BRDF比兰伯特漫反射BRDF复杂得多。对于漫反射光照，无论材质和观察方向如何，余弦波瓣(cosine lobe)都是相同的。但是镜面波瓣(specular lobe)根据观察方向、材质的粗糙度以及F0的菲尼尔项的不同而变化。本来使用查找表(lookup table,LUT)需要四个参数(观察方向是二维的)，但《光环3》中针对球谐函数镜面反射提出了更好的方法。当视线沿着局部Z轴(面法线)旋转时，镜面波瓣的形状不会变化，只有当视线与局部Z轴的夹角发生改变时波瓣形状才会改变(可认为视线绕局部X轴旋转)。因此可以按局部X轴的所有可能的视线方向预计算系数，这样产生的波瓣与实际的观察方向就可以对齐，如图所示： 下图展示了计算L2球谐函数光照贴图得到的间接镜面反射项。 使用球谐函数的方法有个常见的问题——“Ringing”现象。当一侧有强光时，在另一侧就会产生负的波瓣，其值就会非常低甚至是负值。对于2D光照贴图不是大问题，因为光照贴图只与面法线的半球入射辐率有关。但对于存储了整个球体的辐射率或辐射度的探针来讲就会有问题。Peter-Pike Sloan提出了一个解决方案，将窗口函数(windowing function)应用于球谐函数的系数，过滤掉Ringing现象，但窗口函数会引入额外的模糊。下图分别展示了蒙特卡洛积分离线渲染结果、投影辐射率到L2球谐函数并计算辐射度产生Ringing现象、应用窗口函数后的效果修正。","categories":[{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"球面高斯","slug":"球面高斯","permalink":"https://cuihongzhi1991.github.io/tags/%E7%90%83%E9%9D%A2%E9%AB%98%E6%96%AF/"},{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"光照贴图","slug":"光照贴图","permalink":"https://cuihongzhi1991.github.io/tags/%E5%85%89%E7%85%A7%E8%B4%B4%E5%9B%BE/"}]},{"title":"UE4使用插件创建Global Shader","slug":"ueglobalshader","date":"2020-04-28T14:19:15.000Z","updated":"2020-04-28T14:51:23.876Z","comments":true,"path":"2020/04/28/ueglobalshader/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/04/28/ueglobalshader/","excerpt":"UE4的Global Shader在很久之前的版本就有了，并且底层的渲染管线也是使用Global Shader渲染Light Shaft、Volumetric Fog等等。而且由于版本的更迭，很多设置参数的方式和调用的函数都渐渐改变。虽然旧的一些特性依然使用原来的方式，但新的一些特性如4.24的大气系统都开始使用新的方式。本文记录的就是4.24版本使用较新的方式设置参数，传递参数以及调用函数的方法。","text":"UE4的Global Shader在很久之前的版本就有了，并且底层的渲染管线也是使用Global Shader渲染Light Shaft、Volumetric Fog等等。而且由于版本的更迭，很多设置参数的方式和调用的函数都渐渐改变。虽然旧的一些特性依然使用原来的方式，但新的一些特性如4.24的大气系统都开始使用新的方式。本文记录的就是4.24版本使用较新的方式设置参数，传递参数以及调用函数的方法。 创建插件使用UE4.24版本创建空插件模板，命名CustomGlobalShader。 之后会将渲染逻辑和游戏逻辑分别写在两个模块中，CustomGlobalShader.uplugin中填写需要加载的模块。 为两个模块分别创建两个文件夹，并且创建Shaders文件夹作为shader路径 ShaderDeclaration模块创建模块首先修改.Build.cs文件，添加依赖的模块，如Renderer, RendererCore, RHI和Projects。123456789101112using UnrealBuildTool;public class ShaderDeclaration : ModuleRules&#123; public ShaderDeclaration(ReadOnlyTargetRules Target) : base(Target) &#123; PCHUsage = PCHUsageMode.UseExplicitOrSharedPCHs; PrivateDependencyModuleNames.AddRange( new string[] &#123; \"Core\", \"CoreUObject\", \"Engine\", \"Renderer\", \"RenderCore\", \"RHI\", \"Projects\" &#125;); &#125;&#125; ShaderDeclaration.h因为在插件中已经有了模块接口，直接用它与Renderer交互即可。并且提供了将游戏模块与渲染hook解耦的优点，允许更安全和简单的清理。随着4.22的到来，API中可以看到Renderer被大改成更现代的使用方式，就像DX12一样。最大的区别是现在必须将渲染代码封装到一个Render Graph或者Render Pass中。两者各有优点。 Render graphs在UE4中，如果要处理较大的渲染作业并使用引擎池的渲染目标，通常会使用graph。由于引擎现在为了渲染任务专门使用任务graph。使用前从案例中学习也是更简单正确的方式。然而与UObject渲染资源（如Utextures）交互时就非常难用，所以可以使用Render pass来代替。graph通常在应对大体量作业时比较好，对于小规模的作业可以使用Render pass。 Render passesPasses与之前的图形API类似，现在使用光栅化的时候会使用Pass。现在可以创建一个渲染Pass，而不是为光栅化操作设置渲染目标。不使用光栅化的操作（如计算、拷贝和其他操作）可以像之前一样直接使用RHICommandList。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#pragma once#include \"CoreMinimal.h\"#include \"Modules/ModuleManager.h\"#include \"Runtime/Engine/Classes/Engine/TextureRenderTarget2D.h\" // UTextureRenderTarget2D#include \"RenderGraphResources.h\" // IPooledRenderTargetstruct FShaderUsageParameters&#123; UTextureRenderTarget2D* RenderTarget; FColor InputColor; FIntPoint GetRenderTargetSize() const &#123; return CachedRenderTargetSize; &#125; FShaderUsageParameters() &#123;&#125; FShaderUsageParameters(UTextureRenderTarget2D* InRenderTarget) : RenderTarget(InRenderTarget) , InputColor(FColor::White) &#123; CachedRenderTargetSize = RenderTarget ? FIntPoint(RenderTarget-&gt;SizeX, RenderTarget-&gt;SizeY) : FIntPoint::ZeroValue; &#125;private: FIntPoint CachedRenderTargetSize;&#125;;class SHADERDECLARATION_API FShaderDeclarationModule : public IModuleInterface&#123;public: static inline FShaderDeclarationModule&amp; Get() &#123; return FModuleManager::LoadModuleChecked&lt;FShaderDeclarationModule&gt;(\"ShaderDeclaration\"); &#125; static inline bool IsAvailable() &#123; return FModuleManager::Get().IsModuleLoaded(\"ShaderDeclaration\"); &#125; virtual void StartupModule() override; virtual void ShutdownModule() override;public: // 想hook renderer开始渲染时可以调用该方法。每帧都会执行着色器。 void BeginRendering(); // 结束时，调用停止绘制函数 void EndRendering(); // 需要分享新参数时就调用该方法。可以在保存locking和GPU传输时的不同间隙设置它来更新不同的属性集 void UpdateParameters(FShaderUsageParameters&amp; DrawParameters);private: TRefCountPtr&lt;IPooledRenderTarget&gt; UserRenderTarget; FShaderUsageParameters CachedShaderUsageParameters; FDelegateHandle OnPostResolvedSceneColorHanndle; FCriticalSection RenderEveryFrameLock; volatile bool bCachedParametersValid; void PostResolveSceneColor_RenderThread(FRHICommandListImmediate&amp; RHICmdList, class FSceneRenderTargets&amp; SceneContext); void Draw_RenderThread(const FShaderUsageParameters&amp; DrawParameters);&#125;; ShaderDeclaration.cpp游戏线程会调用以下的方法，开始渲染、停止渲染、更新参数等等。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#include \"ShaderDeclaration.h\"#include \"SimpleColor.h\"#include \"Misc/Paths.h\" // FPath#include \"Interfaces/IPluginManager.h\" // IPluginManager#include \"RenderGraphBuilder.h\" // Debug stat macro#include \"RenderTargetPool.h\" // GRenderTargetPoolIMPLEMENT_MODULE(FShaderDeclarationModule, ShaderDeclaration)// 声明一些GPU统计数据，后续方便追踪DECLARE_GPU_STAT_NAMED(GlobalShaderPlugin_Render, TEXT(\"GlobalShaderPlugin: Root Render\"));DECLARE_GPU_STAT_NAMED(GlobalShaderPlugin_Pixel, TEXT(\"GlobalShaderPlugin: Render Pixel Shader\"));void FShaderDeclarationModule::StartupModule()&#123; OnPostResolvedSceneColorHanndle.Reset(); bCachedParametersValid = false; // 映射虚拟的着色器资源路径到插件实际的着色器路径 FString GlobalShaderDir = FPaths::Combine(IPluginManager::Get().FindPlugin(TEXT(\"CustomGlobalShader\"))-&gt;GetBaseDir(), TEXT(\"Shaders\")); AddShaderSourceDirectoryMapping(TEXT(\"/CustomShaders\"), GlobalShaderDir);&#125;void FShaderDeclarationModule::ShutdownModule()&#123; EndRendering();&#125;void FShaderDeclarationModule::BeginRendering()&#123; if (OnPostResolvedSceneColorHanndle.IsValid()) &#123; return; &#125; bCachedParametersValid = false; // 获取Renderer模块 const FName RendererModuleName(\"Renderer\"); IRendererModule* RendererModule = FModuleManager::GetModulePtr&lt;IRendererModule&gt;(RendererModuleName); if (RendererModule) &#123; OnPostResolvedSceneColorHanndle = RendererModule-&gt;GetResolvedSceneColorCallbacks().AddRaw(this, &amp;FShaderDeclarationModule::PostResolveSceneColor_RenderThread); &#125;&#125;void FShaderDeclarationModule::EndRendering()&#123; if (!OnPostResolvedSceneColorHanndle.IsValid()) &#123; return; &#125; const FName RendererModuleName(\"Renderer\"); IRendererModule* RendererModule = FModuleManager::GetModulePtr&lt;IRendererModule&gt;(RendererModuleName); if (RendererModule) &#123; RendererModule-&gt;GetResolvedSceneColorCallbacks().Remove(OnPostResolvedSceneColorHanndle); &#125; OnPostResolvedSceneColorHanndle.Reset();&#125;void FShaderDeclarationModule::UpdateParameters(FShaderUsageParameters&amp; DrawParameters)&#123; RenderEveryFrameLock.Lock(); CachedShaderUsageParameters = DrawParameters; bCachedParametersValid = true; RenderEveryFrameLock.Unlock();&#125;void FShaderDeclarationModule::PostResolveSceneColor_RenderThread(FRHICommandListImmediate&amp; RHICmdList, class FSceneRenderTargets&amp; SceneContext)&#123; if (!bCachedParametersValid) &#123; return; &#125; // 根据数据可以选择是否锁，添加此代码只是为了演示如何锁 RenderEveryFrameLock.Lock(); FShaderUsageParameters Copy = CachedShaderUsageParameters; RenderEveryFrameLock.Unlock(); Draw_RenderThread(Copy);&#125;void FShaderDeclarationModule::Draw_RenderThread(const FShaderUsageParameters&amp; DrawParameters)&#123; check(IsInRenderingThread()); if (!DrawParameters.RenderTarget) &#123; return; &#125; FRHICommandListImmediate&amp; RHICmdList = GRHICommandList.GetImmediateCommandList(); QUICK_SCOPE_CYCLE_COUNTER(STAT_GlobalShaderPlugin_Render); // 为UE4前端收集CPU分析数据 SCOPED_DRAW_EVENT(RHICmdList, GlobalShaderPlugin_Render); // 为分析GPU活动添加的元数据，可以用RenderDoc这种工具查看 if (!UserRenderTarget.IsValid()) &#123; // 创建缓存RT描述符，FPooledRenderTarget是渲染线程允许共享和纹理可视化的渲染目标。 FPooledRenderTargetDesc UserRenderTargetDesc(FPooledRenderTargetDesc::Create2DDesc(DrawParameters.GetRenderTargetSize(), PF_R32_UINT, FClearValueBinding::None, TexCreate_None, TexCreate_ShaderResource | TexCreate_UAV, false)); UserRenderTargetDesc.DebugName = TEXT(\"GlobalShaderPlugin_UserRenderTarget\"); // 如果旧元素依然有效则返回true, 分配了新元素则返回false GRenderTargetPool.FindFreeElement(RHICmdList, UserRenderTargetDesc, UserRenderTarget, TEXT(\"GlobalShaderPlugin_UserRenderTarget\")); &#125; FSimpleColor::DrawToRenderTarget_RenderThread(RHICmdList, DrawParameters, UserRenderTarget-&gt;GetRenderTargetItem().TargetableTexture);&#125; SimpleColor.h声明一个简单着色器的绘制函数12345678910#pragma once#include \"CoreMinimal.h\"#include \"ShaderDeclaration.h\"class FSimpleColor&#123;public: static void DrawToRenderTarget_RenderThread(FRHICommandListImmediate&amp; RHICmdList, const FShaderUsageParameters&amp; DrawParameters, FTextureRHIRef UserRenderTarget);&#125;; SimpleColor.cpp此处会创建两个Global Shader，分别是顶点着色器和像素着色器。并且通过IMPLEMENT_GLOBAL_SHADER()进行绑定。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#include \"SimpleColor.h\"#include \"Containers/DynamicRHIResourceArray.h\" // TResourceArray#include \"Runtime/RenderCore/Public/PixelShaderUtils.h\" // FFilterVertex// 基础的静态顶点缓冲class FSimpleScreenVertexBuffer : public FVertexBuffer&#123;public: // 为渲染资源初始化RHI void InitRHI() &#123; // FFilterVertex 表示顶点数据是用来过滤纹理的， VERTEXBUFFER_ALIGNMENT 是内存分配时的对齐方式 TResourceArray&lt;FFilterVertex, VERTEXBUFFER_ALIGNMENT&gt; Vertices; Vertices.SetNumUninitialized(6); Vertices[0].Position = FVector4(-1, 1, 0, 1); Vertices[0].UV = FVector2D(0, 0); Vertices[1].Position = FVector4(1, 1, 0, 1); Vertices[1].UV = FVector2D(1, 0); Vertices[2].Position = FVector4(-1, -1, 0, 1); Vertices[2].UV = FVector2D(0, 1); Vertices[3].Position = FVector4(1, -1, 0, 1); Vertices[3].UV = FVector2D(1, 1); // 创建顶点缓冲区， 用上方创建的初始数据填充该缓冲 FRHIResourceCreateInfo CreateInfo(&amp;Vertices); VertexBufferRHI = RHICreateVertexBuffer(Vertices.GetResourceDataSize(), BUF_Static, CreateInfo); &#125;&#125;;// 声明一个顶点缓冲TGlobalResource&lt;FSimpleScreenVertexBuffer&gt; GSimpleScreenVertexBuffer;// 基础的顶点着色器class FSimpleColorVS : public FGlobalShader&#123;public: DECLARE_GLOBAL_SHADER(FSimpleColorVS); static bool ShouldCompilePermutation(const FGlobalShaderPermutationParameters&amp; Parameters) &#123; return true; &#125; static void ModifyCompilationEnvironment(const FGlobalShaderPermutationParameters&amp; Parameters, FShaderCompilerEnvironment&amp; OutEnvironment) &#123; FGlobalShader::ModifyCompilationEnvironment(Parameters, OutEnvironment); &#125; FSimpleColorVS() &#123;&#125; FSimpleColorVS(const ShaderMetaType::CompiledShaderInitializerType&amp; Initializer) : FGlobalShader(Initializer) &#123;&#125;&#125;;// 像素着色器，参数作为cpp和HLSL的桥梁class FSimpleColorPS : public FGlobalShader&#123;public: DECLARE_GLOBAL_SHADER(FSimpleColorPS); SHADER_USE_PARAMETER_STRUCT(FSimpleColorPS, FGlobalShader); // 和游戏线程的参数一一对应 BEGIN_SHADER_PARAMETER_STRUCT(FParameters,) SHADER_PARAMETER(FVector4, InputColor) END_SHADER_PARAMETER_STRUCT() static bool ShouldCompilePermutation(const FGlobalShaderPermutationParameters&amp; Parameters) &#123; return IsFeatureLevelSupported(Parameters.Platform, ERHIFeatureLevel::SM5); &#125; static void ModifyCompilationEnvironment(const FGlobalShaderPermutationParameters&amp; Parameters, FShaderCompilerEnvironment&amp; OutEnvironment) &#123; FGlobalShader::ModifyCompilationEnvironment(Parameters, OutEnvironment); &#125;&#125;;// 告诉引擎创建着色器以及着色器的入口位置 // 着色器类型 着色器路径 着色器函数名 类型IMPLEMENT_GLOBAL_SHADER(FSimpleColorVS, \"/CustomShaders/PixelShader.usf\", \"MainVertexShader\", SF_Vertex);IMPLEMENT_GLOBAL_SHADER(FSimpleColorPS, \"/CustomShaders/PixelShader.usf\", \"MainPixelShader\", SF_Pixel);void FSimpleColor::DrawToRenderTarget_RenderThread(FRHICommandListImmediate&amp; RHICmdList, const FShaderUsageParameters&amp; DrawParameters, FTextureRHIRef UserRenderTarget)&#123; QUICK_SCOPE_CYCLE_COUNTER(STAT_CustomGlobalShaderPlugin_PixelShader); // 为UE4前端收集CPU分析数据 SCOPED_DRAW_EVENT(RHICmdList, CustomGlobalShaderPlugin_Pixel); // 为分析GPU活动添加的元数据，可以用RenderDoc这种工具查看 FRHIRenderPassInfo RenderPassInfo(DrawParameters.RenderTarget-&gt;GetRenderTargetResource()-&gt;GetRenderTargetTexture(), ERenderTargetActions::Clear_Store); RHICmdList.BeginRenderPass(RenderPassInfo, TEXT(\"CustomGlobalShaderPlugin_OutputToRenderTarget\")); auto ShaderMap = GetGlobalShaderMap(GMaxRHIFeatureLevel); TShaderMapRef&lt;FSimpleColorVS&gt; VertexShader(ShaderMap); TShaderMapRef&lt;FSimpleColorPS&gt; PixelShader(ShaderMap); // 设置图形管线状态 FGraphicsPipelineStateInitializer GraphicsPSOInit; RHICmdList.ApplyCachedRenderTargets(GraphicsPSOInit); GraphicsPSOInit.BlendState = TStaticBlendState&lt;&gt;::GetRHI(); GraphicsPSOInit.RasterizerState = TStaticRasterizerState&lt;&gt;::GetRHI(); GraphicsPSOInit.DepthStencilState = TStaticDepthStencilState&lt;false, CF_Always&gt;::GetRHI(); GraphicsPSOInit.BoundShaderState.VertexDeclarationRHI = GFilterVertexDeclaration.VertexDeclarationRHI; GraphicsPSOInit.BoundShaderState.VertexShaderRHI = GETSAFERHISHADER_VERTEX(*VertexShader); GraphicsPSOInit.BoundShaderState.PixelShaderRHI = GETSAFERHISHADER_PIXEL(*PixelShader); GraphicsPSOInit.PrimitiveType = PT_TriangleStrip; SetGraphicsPipelineState(RHICmdList, GraphicsPSOInit); // 设置像素着色器颜色，将游戏线程的参数传进来 FSimpleColorPS::FParameters PassParameters; PassParameters.InputColor = FVector4(DrawParameters.InputColor.R, DrawParameters.InputColor.G, DrawParameters.InputColor.B, DrawParameters.InputColor.A) / 255.0f; // 提交参数到RHI命令列表 SetShaderParameters(RHICmdList, *PixelShader, PixelShader-&gt;GetPixelShader(), PassParameters); // 绘制 RHICmdList.SetStreamSource(0, GSimpleScreenVertexBuffer.VertexBufferRHI, 0); RHICmdList.DrawPrimitive(0, 2, 1); // 完成渲染目标 RHICmdList.CopyToResolveTarget(DrawParameters.RenderTarget-&gt;GetRenderTargetResource()-&gt;GetRenderTargetTexture(), DrawParameters.RenderTarget-&gt;GetRenderTargetResource()-&gt;TextureRHI, FResolveParams()); RHICmdList.EndRenderPass();&#125; PixelShader.usf着色器的声明模块基本结束。需要创建与之对应的着色器文件.usf放在Shaders文件夹。1234567891011121314// VERTEX SHADERvoid MainVertexShader(float4 InPosition : ATTRIBUTE0, float2 InUV : ATTRIBUTE1, out float2 OutUV : TEXCOORD0, out float4 OutPosition : SV_POSITION)&#123; OutPosition = InPosition; OutUV = InUV;&#125;// PIXEL SHADERfloat4 InputColor;void MainPixelShader(in float2 uv : TEXCOORD0, out float4 OutColor : SV_Target0)&#123; OutColor = InputColor;&#125; 着色器应用模块创建模块首先修改.Build.cs文件，添加依赖的模块，如上面创建的ShaderDeclaration12345678910111213using UnrealBuildTool;public class ShaderUsage : ModuleRules&#123; public ShaderUsage(ReadOnlyTargetRules Target) : base(Target) &#123; PCHUsage = PCHUsageMode.UseExplicitOrSharedPCHs; PublicDependencyModuleNames.AddRange( new string[] &#123; \"Core\", \"CoreUObject\", \"Engine\", \"RHI\", \"ShaderDeclaration\" &#125;); &#125;&#125; ShaderUsage.h基本的模块功能。123456789101112131415161718#pragma once#include \"CoreMinimal.h\"#include \"Modules/ModuleManager.h\"class FShaderUsageModule : public IModuleInterface&#123;public: static inline FShaderUsageModule&amp; Get() &#123; return FModuleManager::LoadModuleChecked&lt;FShaderUsageModule&gt;(\"ShaderUsage\"); &#125; static inline bool IsAvailable() &#123; return FModuleManager::Get().IsModuleLoaded(\"ShaderUsage\"); &#125;&#125;; ShaderUsage.cpp123#include \"ShaderUsage.h\"IMPLEMENT_MODULE(FShaderUsageModule, ShaderUsage) TestActor.h创建一个测试Actor类。123456789101112131415161718192021#pragma once#include \"CoreMinimal.h\"#include \"GameFramework/Actor.h\"#include \"TestActor.generated.h\"UCLASS()class ATestActor : public AActor&#123; GENERATED_BODY()public: UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = GlobalShader) FColor InputColor; UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = GlobalShader) class UTextureRenderTarget2D* UserRenderTarget;public: virtual void BeginPlay() override; virtual void BeginDestroy() override; virtual void Tick(float DeltaTime) override;&#125;; TestActor.cpp1234567891011121314151617181920212223242526#include \"TestActor.h\"#include \"ShaderDeclaration.h\"void ATestActor::BeginPlay()&#123; Super::BeginPlay(); FShaderDeclarationModule::Get().BeginRendering();&#125;void ATestActor::BeginDestroy()&#123; FShaderDeclarationModule::Get().EndRendering(); Super::BeginDestroy();&#125;void ATestActor::Tick(float DeltaTime)&#123; Super::Tick(DeltaTime); FShaderUsageParameters DrawParameters(UserRenderTarget); &#123; DrawParameters.InputColor = InputColor; &#125; FShaderDeclarationModule::Get().UpdateParameters(DrawParameters);&#125; 目前应用模块也已经完成，编译完成后，在引擎中测试效果。 测试结果首先以TestActor为父类创建蓝图类。然后创建一个RT，和一个使用该RT的材质。蓝图类中添加一个Box，并使用该测试材质。EventTick每帧传入随机的颜色，Play一下便可以看到颜色不断变化的Box了。","categories":[{"name":"Unreal Engine","slug":"Unreal-Engine","permalink":"https://cuihongzhi1991.github.io/categories/Unreal-Engine/"}],"tags":[{"name":"UE4","slug":"UE4","permalink":"https://cuihongzhi1991.github.io/tags/UE4/"},{"name":"材质","slug":"材质","permalink":"https://cuihongzhi1991.github.io/tags/%E6%9D%90%E8%B4%A8/"},{"name":"渲染管线","slug":"渲染管线","permalink":"https://cuihongzhi1991.github.io/tags/%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"}]},{"title":"UE4.22+ 添加自定义卡通着色模型","slug":"ue4addshadingmodel","date":"2020-04-25T06:14:25.000Z","updated":"2020-04-28T13:19:35.113Z","comments":true,"path":"2020/04/25/ue4addshadingmodel/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/04/25/ue4addshadingmodel/","excerpt":"UE4中内置了一些着色模型(Shading Model)，基本满足了绝大部分游戏开发的需求。但一些特殊美术风格的游戏也许需要自定义着色模型，比如当下火热的二次元向游戏。本文记录了4.22+版本添加自定义着色模型的方法。","text":"UE4中内置了一些着色模型(Shading Model)，基本满足了绝大部分游戏开发的需求。但一些特殊美术风格的游戏也许需要自定义着色模型，比如当下火热的二次元向游戏。本文记录了4.22+版本添加自定义着色模型的方法。 创建自定义着色模型添加着色模型类型在EngineTypes.h中为自定义的着色模型添加一个新的UENUM。MaterialShader.cpp 添加一个枚举只是可以在材质编辑器看到而已，必须要定义这个着色模型。首先要设置编译这个着色器的环境。通过SetDefine()实现。SetDefine()函数的作用是为着色器添加一个属性的#define预处理器，编译着色器时就知道按照何种着色模型去编译。下面的代码就会让着色器编译器将MATERIAL_SHADINGMODEL_CEL_SHADING认作1.HLSLMaterialTranslator.h 开启材质引脚将会使用CustomData0和1作为Cel Bands和Outline Thickness的引脚。只需要在Material.cpp中的MP_CustomData0和MP_CustomData1之后添加开启条件。 CustomData可以保持CustomData0或1的引脚名称，也可以自定义名字。在MaterialGraph.cpp中的GetCustomDataPinName()中添加着色模型对应的引脚名称。 另外CustomData0和1的范围是0到1，所以大于1的数值n操作最好用1/n做后续数学计算。可以在AllocGBufferTargets()函数中看到UE4使用的是B8G8R8A8存储GBuffer的，CustomData的数据是储存在R或G通达的，8-bit小数最大值会被限制1.0。 借Refraction的引脚修改case MP_Refraction引脚的激活条件。 但是编译材质图标节点到着色器代码时，UE会检查冗余和不持支的内容，不支持的部分就会丢弃掉，或者被默认值代替。在HLSLMaterialTranslator.h的Translate()中，Refraction引脚只有混合模式为半透的时候才会编译，所以修改一下编译条件。 在MaterialGraph.cpp的RebuildGraph()函数中可以修改Refraction引脚名称的实现方式，用GetRefractionPinName()函数获取最终名称。 现在已经修改好所有的cpp和h文件,可以编译引擎工程。 修改着色器：BasePass和GBuffer建立着色模型ID和颜色在ShadingCommon.ush中定义新的SHADINGMODELID，并设置ID和颜色 为了让GBuffer输出CustomData，需要在BasePassCommon.ush中扩展输出条件 输出GBuffer数据的准备工作ShadingModelsMaterial.ush中的SetGBufferForShadingModel()函数会设置GBuffer的数据，添加Cel着色模型的情况。 但是Refraction引脚的数据需要用GetMaterialRefraction(FPixelMaterialInputs PixelMaterialInputs)，可以在BasePassPixelShader.ush中使用PixelMaterialInpus输入参数得到Refraction引脚的数据。 修改着色器：DeferredPass和Lighting光照调整DeferredLightPixelMain()函数在DeferredLightPixelShaders.usf中。颜色是通过GetDynamicLighting()函数实现的，该函数位于DeferredLightingCommon.ush中。首先获取阴影项，然后调用函数IntegrateBxDF()函数得到光照项。在该函数中，不同的着色模型会执行不同的BxDF()，所以可以在ShadingModels.ush的IntegratedBxDF()函数中添加CelShadingBxDF()。可以以DefaultLitBxDF()为基础修改和扩展。 阴影调整阴影还是默认的柔和，在GetDynamicLighting()中的IntegrateBxDF()前调用了GetShadowTerms()。在计算光照颜色的时候将LightColor与LightMask和Shadow.SurfaceShadow进行了相乘。所以只需要对LightMask和Shadow.SurfaceShadow进行一步处理，得到分层的锐利阴影即可。DeferredLightingCommon.ush 反射调整在ReflectionEnvironmentPixelShader.ush文件中加入判断条件，如果是卡通着色模型，就转为LAB格式调整亮度再转回RGB。 描边因为是延迟渲染，所以可以在延迟光照的步骤可以拿到深度和法线做描边。 修改代码在DeferredLightPixelShaders.usf的DeferredLightPixelMain()中添加函数CalcSceneDepth()。SceneTexturesStruct包含了GBufferA/B/C/DTexture，场景深度就在其中。法线存在GBufferA。","categories":[{"name":"Unreal Engine","slug":"Unreal-Engine","permalink":"https://cuihongzhi1991.github.io/categories/Unreal-Engine/"}],"tags":[{"name":"UE4","slug":"UE4","permalink":"https://cuihongzhi1991.github.io/tags/UE4/"},{"name":"材质","slug":"材质","permalink":"https://cuihongzhi1991.github.io/tags/%E6%9D%90%E8%B4%A8/"},{"name":"卡通着色","slug":"卡通着色","permalink":"https://cuihongzhi1991.github.io/tags/%E5%8D%A1%E9%80%9A%E7%9D%80%E8%89%B2/"},{"name":"渲染管线","slug":"渲染管线","permalink":"https://cuihongzhi1991.github.io/tags/%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"}]},{"title":"UE4.22+ 添加Uniform","slug":"ue4uniform","date":"2020-04-23T05:10:39.000Z","updated":"2020-04-28T13:19:40.526Z","comments":true,"path":"2020/04/23/ue4uniform/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/04/23/ue4uniform/","excerpt":"Uniform是一种从CPU中的应用向GPU中的着色器发送数据的方式，Uniform是全局的(Global)。全局意味着uniform变量必须在每个着色器程序对象中都是独一无二的，而且它可以被着色器程序的任意着色器在任意阶段访问。第二，无论你把Uniform值设置成什么，Uniform会一直保存它们的数据，直到它们被重置或更新。UE4的材质编辑器可以调用的红色节点中很多就是Uniform，如ObjectBounds，ActorPosition等等。本文记录了如何在UE4.22或更高版本添加自定义的Uniform，并且生成材质节点在任意材质中调用，该Uniform值也将显示在场景的Skylight组件上供用户修改。","text":"Uniform是一种从CPU中的应用向GPU中的着色器发送数据的方式，Uniform是全局的(Global)。全局意味着uniform变量必须在每个着色器程序对象中都是独一无二的，而且它可以被着色器程序的任意着色器在任意阶段访问。第二，无论你把Uniform值设置成什么，Uniform会一直保存它们的数据，直到它们被重置或更新。UE4的材质编辑器可以调用的红色节点中很多就是Uniform，如ObjectBounds，ActorPosition等等。本文记录了如何在UE4.22或更高版本添加自定义的Uniform，并且生成材质节点在任意材质中调用，该Uniform值也将显示在场景的Skylight组件上供用户修改。 创建CPU中的数据结构体FShaderParametersMetadata这是一个4.22的新类，4.21有一个类似的结构体FUniformBufferStruct。4.22中可以在ShaderParameterMetadata.h中找到这个类。FShaderParametersMetadata是一个储存了多个着色器参数的集合或容器。该容器可以储存不同数据类型的参数。每个参数都是一个成员，可以是矩阵、向量、数组或者纹理。（提示：FShaderParameter.h中还定义了另外一个着色器参数系统。有FShaderParameter, FShaderResourceParameter, FShaderUniformBufferParameter等等。依然可以在单独的着色器中使用，如在LightRendering.cpp中一样。）如果要定义一组着色器参数，可以用宏来声明这些元数据，这是将它们放进UniformBuffer的快捷办法。 ShaderParameterMacros.h这个头文件中包含了一些声明参数结构体的宏。比如BEGIN_GLOBAL_SHADER_PARAMETER_STRUCT()和END_GLOBAL_SHADER_PARAMETER_STRUCT()。这两个宏创建了一个类作为ParameterMetadata的壳，如：123456789// Begin Macro:class STRUCT_NAME &#123;static Metadata;CreateUniformBuffer() (when declare as GLOBAL)...Parameter Macro: Insert all members (Parameter)...// End:some ending stuff + &#125;对于全局的参数结构体，cpp中需要添加另外一个宏： IMPLEMENT_GLOBAL_SHADER_PARAMETER_STRUCT(FMyParameterStruct, “MyShaderBindingName”);这个宏将静态的元数据放入一个全局的容器，扩展后的宏类似下方：12FShaderParametersMetadata StructTypeName::Metadata(...);=&gt; FShaderParametersMetadata(..) &#123; Add-Self-To-Global-Container &#125;现在有了元数据的壳，可以开始使用SHADER_PARAMETER(Type, Name) 添加一些参数到壳中，用类型和名称创建一个成员，然后添加该成员到元数据的成员数组中。（提示：有两个版本的声明：GLOBAL和LOCAL，区别是GLOBAL会在类中创建一个UniformBuffer并且所有成员会放进这个缓冲中，另外GLOBAL会将元数据保存在全局的map和list中。而LOCAL方式不会创建内在的UniformBuffer，所以不用调用IMPLEMENT_宏。) 案例：Primitive Uniform, View Uniform可以参考一下PrimitiveUniform和ViewUniform，两个最重要的UniformShaderParameters。 PrimitiveUniformShaderParameters.h该头文件中声明了一个FPrimitiveUniformShaderParameters的结构体。之所以比较重要是因为在检索着色器代码的时候经常会看到”Primitive”或”GetPrimitiveData()“这样的变量，都是来自这个uniform结构体的。它保存了一个图元（或图元组件）的信息，包括LocalToWorld, WorldToLocal等等。 FViewUniformShaderParameters(SceneView.h)可以认为这是当前视图相关的场景信息，包括相机的信息，游戏时间或者其他渲染需要的信息。这也是一个适合添加自定义全局Uniform参数的地方。在这个ShaderParameters中， 4.22加入了StructuredBuffer类型，可以传递数组进StructuredBuffer，名称为PrimitiveSceneData的Buffer包含所有GPU实例化的图元数据。 IMPLEMENT_Macro(SceneView.cpp)上文提到过，实现宏创建元数据并且保存到全局的容器中。另外，这个宏也会帮助着色器编译器为GPU生成着色器代码。例如着色器编译器会生成一个”cbuffer Primitive{}”和”cbuffer View{}”，名称是传进宏里的名称。cbuffer的内容也是从FPrimitiveUniformShaderParameters或FViewUniformShaderParameters反射的。 （提示：当不支持自动实例化时，就会使用cubuffer Primitive，因此每个Drawcall现在的图元会绑定它的UniformBuffer到cbuffer。当自动实例化开启是，就不使用这个cbuffer了，而是使用ViewUniform中的StructuredArray”PrimitiveSceneData” 。） GPU：生成着色器代码之前讨论过，cbuffer结构中的着色器代码在任何.ush文件中都没有预先定义，它们是在编译着色器的时候生成的。下面大致看下原理。1234567891011121314151617181920212223242526272829303132333435363738394041//////////////////////// ShaderCompiler.cpp//////////////////////void GlobalBeginCompileShader(…)&#123; … // 设置编译标识，添加任务到队列，编译器稍后会调用该任务 NewJobs.Add(NewJob);&#125;//////////////////////////// ShaderCompileWorker.cpp//////////////////////////static void ProcessCompilationJob(…)&#123; ... // 调用ShaderFormatD3D.cpp::CompileShader() (D3D) Compiler-&gt;CompileShader(…);&#125;////////////////////////// D3DShaderCompiler.cpp////////////////////////void CompileShader_Windows_SM5(…)&#123; … CompileD3DShader(…);&#125;void CompileD3DShader(…)&#123; … if (Input.RootParameterBindings.Num()) &#123; // 生成全局ShaderParameters的cbuffer代码，将字符串放在PreprocessedShaderSource中 MoveShaderParametersToRootConstantBuffer(Input, PreprocessedShaderSource); &#125; // 处理字符串：修改代码便于从\"cbuffer.memberData\"到\"cbuffer_memberData\"的代码允许cbuffer访问。 RemoveUniformBuffersFromSource(Input.Environment, PreprocessedShaderSource); …&#125;着色器代码是在MoveShaderParametersToRootConstantBuffer()中生成的，然后RemoveUniformBuffersFromSource()会对着色器代码进行调整。[cbuffer_name].[dataMember]会转化成[cbuffer_name]_[dataMember]，例如View.LocalToWorld会变成View_LocalToWorld。 1234567891011121314151617181920212223242526// ShaderCompilerCommon.cpp:void MoveShaderParametersToRootConstantBuffer(…)&#123; … /* Print the string \"cbuffer &#123;…&#125;\" , but looks like this is still an intermediate code, the string will be proccessed later again, but I don't trace too much in this part */ // 输出字符串\"cbuffer&#123;...&#125;\", 但貌似只是过渡，后面字符串还会被处理一次。 FString NewShaderCode = FString::Printf( TEXT(\"cbuffer %s\\r\\n\") TEXT(\"&#123;\\r\\n\") TEXT(\"%s\") TEXT(\"&#125;\\r\\n\\r\\n%s\"), FShaderParametersMetadata::kRootUniformBufferBindingName, *RootCBufferContent, *PreprocessedShaderSource); PreprocessedShaderSource = MoveTemp(NewShaderCode);&#125;// 交叉编译器还不支持结构体初始化，用名称替换所有的uniform缓冲结构体成员的引用。// 例如View.WorldToClip变成View_WorldToClip，移除结构体的依赖。void RemoveUniformBuffersFromSource(…)&#123; … /* 'OpaqueBasePass.Shared.Reflection .SkyLightCubemapBrightness' -&gt; 'OpaqueBasePass_Shared_Reflection_SkyLightCubemapBrightness ' */ …&#125; 生成的着色器代码下方的两个文件在vs中是找不到的，因为它们是在编译时自动生成的。但是，可以修改着色器编译器设置来显示debug信息。在ConsoleVariables.ini中添加r.Shaders.Optimize=0和r.Shaders.KeepDebugInfo=1。然后就可以用RenderDoc抓帧查看资源包括着色器代码。在View.ush和Primitive.ush中，可以看到cbuffer的内容与C++宏声明的着色器参数是一一对应的，而变量的前缀则是结构体的名称。 更新和绑定缓冲更新缓冲和绑定缓冲是不同的。更新需要获取参数的数据然后更新数据到UniformBuffer；绑定缓冲是告诉着色器我们将要使用哪些缓冲。例如，我们有十个UniformBuffer，它们是不同Views, Primitivies等等的缓冲，它们会在任意的drawcall前更新。但是渲染一个模型时，如果着色器只需要十个中的两个，只需要绑定其中的两个缓冲到着色器。 SceneRendering.cpp不同的uniform参数可以有自己的更新管线，所以它们可以在不同的地方更新。这里会展示一下更新ViewUniformBufferParameter的位置。从DeferredShadingRenderer.cpp::Render()可以追踪到InitViews()，最后到SceneRendering.cpp::SetupUniformBufferParameters()，此处设置了FViewUniformBufferParameter的数据。123456789/* SceneRendering.cpp */void FViewInfo::SetupUniformBufferParameters(…)&#123; … SetupCommonViewUniformBufferParameters(…); …&#125;/* SceneView.cpp */void FSceneView::SetupCommonViewUniformBufferParameters()&#123;…&#125; ClobalShader.h这是绑定缓冲的地方，同样地，不同的渲染pass可以在不同的地方绑定缓冲。发送drawcall的时候缓冲绑定几乎已经完成。因为绑定缓冲意味着链接缓冲到着色器，所以必须同时传递shaderRHI和缓冲到函数中。12345inline void SetParameters(…, ShaderRHI, ViewUniformBuffer)&#123; … SetUniformBufferParameter(…, ShaderRHI, …, ViewUniformBuffer);&#125; D3D11StateCachePrivate.hSetUniformBufferParameter()最终会来到InternalSetSetConstantBuffer()函数，这个函数会调用D3D11 API [Type]SetConstantBuffers到一个顶点/外壳/域/几何/像素/计算着色器。绑定工作在此时完成。123456D3D11_STATE_CACHE_INLINE void InternalSetSetConstantBuffer(…)&#123; … case SF_Vertex: Direct3DDeviceIMContext-&gt;VSSetConstantBuffers(…); break; …&#125; 添加Uniform控制参数添加参数因为要向View添加一个全局uniform，所以在SceneView.h添加一个VIEW_UNIFORM_BUFFER_MEMBER。 更新参数值可以借用SkyLightComponent和Proxy来存放自定义的uniform，在SetupUniformBufferParameters()中可以把用户编辑过的值传到ViewUniform。SceneRendering.cpp： 添加一个新的UPROPERTY”MyCustomClobalUniform”到SceneManagement.h 添加相应的组件变量在SkyLightSceneProxy中——“MyCustomGlobalUniform”。在代理的构造函数中，复制SkyLightComponent的值。SceneManagement.h： 在着色器代码中访问参数在.ush或.usf文件或材质编辑器的Custom节点中都可以使用View.TestConstantUniform来调用该数值了，并且可以在天光组件的参数面板中修改该数值进行全局控制。 创建材质节点添加节点类在引擎的\\Source\\Runtime\\Engine\\Classes\\Materials 路径下存放了材质编辑器的所有节点源文件。每个节点都有自己的UMaterialExpression类。所以同样在此路径创建一个头文件MaterialExpressionMyGlobalUniform.h。因为此案例只是一个向量数据，可以拷贝DeltaTime的节点。确保添加完头文件后重新生成sln，这样可以自动生成.generated.h文件，否则会编译失败。 然后在MaterialExpressions.cpp中实现它的构造函数 节点的编译器设置在MaterialCompiler.h中添加MyCustomUniform()方法。 在HLSLMaterialTranslator.h中，才是MaterialCompiler真正起作用的地方。调用AddInlinedCodeChunk(DATA_TYPE, CODE_STRING)来实现。 测试保存代码，重新成成sln工程，编译并打开引擎。","categories":[{"name":"Unreal Engine","slug":"Unreal-Engine","permalink":"https://cuihongzhi1991.github.io/categories/Unreal-Engine/"}],"tags":[{"name":"UE4","slug":"UE4","permalink":"https://cuihongzhi1991.github.io/tags/UE4/"},{"name":"材质","slug":"材质","permalink":"https://cuihongzhi1991.github.io/tags/%E6%9D%90%E8%B4%A8/"},{"name":"渲染管线","slug":"渲染管线","permalink":"https://cuihongzhi1991.github.io/tags/%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"}]},{"title":"UE4.24 材质Custom节点链接.usf文件","slug":"usf424","date":"2020-04-16T14:19:15.000Z","updated":"2020-04-25T06:29:11.304Z","comments":true,"path":"2020/04/16/usf424/","link":"","permalink":"https://cuihongzhi1991.github.io/2020/04/16/usf424/","excerpt":"UE4材质编辑器中的Custom节点可以写hlsl代码，方便进行一些复杂计算，比如for循环。可以保证材质面板简洁可读性高。UE4之前的版本直接在Custom节点中用#include包含Shaders文件夹下的ush或usf文件，这样可以用外部的代码编辑器编写shader文件。但是最近的版本有所改动，Custom节点无法识别Shaders路径下的文件。所以需要修改工程模块来包含任意路径。","text":"UE4材质编辑器中的Custom节点可以写hlsl代码，方便进行一些复杂计算，比如for循环。可以保证材质面板简洁可读性高。UE4之前的版本直接在Custom节点中用#include包含Shaders文件夹下的ush或usf文件，这样可以用外部的代码编辑器编写shader文件。但是最近的版本有所改动，Custom节点无法识别Shaders路径下的文件。所以需要修改工程模块来包含任意路径。 准备工作 首先创建C++工程，如果是蓝图工程可以添加新的C++类，会自动转成C++工程。假设项目名称为MotionBlur。 修改MotionBlur.Build.cs: 12345678910111213141516using UnrealBuildTool;public class MotionBlur : ModuleRules&#123; public MotionBlur(ReadOnlyTargetRules Target) : base(Target) &#123; PCHUsage = PCHUsageMode.UseExplicitOrSharedPCHs; PublicDependencyModuleNames.AddRange(new string[] &#123; \"Core\", \"CoreUObject\", \"Engine\", \"InputCore\", // 添加依赖模块，旧版是ShaderCore,现在改为RenderCore \"RHI\", \"RenderCore\" &#125;); // 添加依赖项Projects，可以识别工程路径 PrivateDependencyModuleNames.AddRange(new string[] &#123;\"Projects\"&#125;); &#125;&#125; 修改MotionBlur.h: 123456789#pragma once#include \"CoreMinimal.h\"class FMotionBlurModule : public IModuleInterface&#123;public: virtual void StartupModule() override; virtual void ShutdownModule() override;&#125;; 修改MotionBlur.cpp: 12345678910111213141516171819#include \"MotionBlur.h\"#include \"Modules/ModuleManager.h\"#include \"Misc/Paths.h\"#include \"ShaderCore.h\"IMPLEMENT_MODULE(FMotionBlurModule, MotionBlur);void FMotionBlurModule::StartupModule() &#123; // 获取工程路径，并指定usf文件存放的路径为工程的Shaders文件夹 FString ShaderDirectory = FPaths::Combine(FPaths::ProjectDir(), TEXT(\"Shaders\")); // 路径映射Csutom节点直接写#include\"/Project/xxx.usf\"即可 AddShaderSourceDirectoryMapping(\"/Project\", ShaderDirectory);&#125;void FMotionBlurModule::ShutdownModule()&#123; ResetAllShaderSourceDirectoryMappings();&#125; 使用 函数可以放在统一的Custom节点，只有主要执行节点才可以识别输入的参数 .usf文件要放在工程路径下的Shaders文件夹（之前在CPP里自定义的路径）","categories":[{"name":"Unreal Engine","slug":"Unreal-Engine","permalink":"https://cuihongzhi1991.github.io/categories/Unreal-Engine/"}],"tags":[{"name":"UE4","slug":"UE4","permalink":"https://cuihongzhi1991.github.io/tags/UE4/"},{"name":"材质","slug":"材质","permalink":"https://cuihongzhi1991.github.io/tags/%E6%9D%90%E8%B4%A8/"}]}],"categories":[{"name":"Houdini","slug":"Houdini","permalink":"https://cuihongzhi1991.github.io/categories/Houdini/"},{"name":"Unity","slug":"Unity","permalink":"https://cuihongzhi1991.github.io/categories/Unity/"},{"name":"数学","slug":"数学","permalink":"https://cuihongzhi1991.github.io/categories/%E6%95%B0%E5%AD%A6/"},{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Unreal Engine","slug":"Unreal-Engine","permalink":"https://cuihongzhi1991.github.io/categories/Unreal-Engine/"}],"tags":[{"name":"Houdini","slug":"Houdini","permalink":"https://cuihongzhi1991.github.io/tags/Houdini/"},{"name":"VEX","slug":"VEX","permalink":"https://cuihongzhi1991.github.io/tags/VEX/"},{"name":"Unity","slug":"Unity","permalink":"https://cuihongzhi1991.github.io/tags/Unity/"},{"name":"URP","slug":"URP","permalink":"https://cuihongzhi1991.github.io/tags/URP/"},{"name":"材质","slug":"材质","permalink":"https://cuihongzhi1991.github.io/tags/%E6%9D%90%E8%B4%A8/"},{"name":"数学","slug":"数学","permalink":"https://cuihongzhi1991.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"name":"微积分","slug":"微积分","permalink":"https://cuihongzhi1991.github.io/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/"},{"name":"球面高斯","slug":"球面高斯","permalink":"https://cuihongzhi1991.github.io/tags/%E7%90%83%E9%9D%A2%E9%AB%98%E6%96%AF/"},{"name":"图形学","slug":"图形学","permalink":"https://cuihongzhi1991.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"次表面散射","slug":"次表面散射","permalink":"https://cuihongzhi1991.github.io/tags/%E6%AC%A1%E8%A1%A8%E9%9D%A2%E6%95%A3%E5%B0%84/"},{"name":"角色","slug":"角色","permalink":"https://cuihongzhi1991.github.io/tags/%E8%A7%92%E8%89%B2/"},{"name":"光照贴图","slug":"光照贴图","permalink":"https://cuihongzhi1991.github.io/tags/%E5%85%89%E7%85%A7%E8%B4%B4%E5%9B%BE/"},{"name":"UE4","slug":"UE4","permalink":"https://cuihongzhi1991.github.io/tags/UE4/"},{"name":"渲染管线","slug":"渲染管线","permalink":"https://cuihongzhi1991.github.io/tags/%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"},{"name":"卡通着色","slug":"卡通着色","permalink":"https://cuihongzhi1991.github.io/tags/%E5%8D%A1%E9%80%9A%E7%9D%80%E8%89%B2/"}]}